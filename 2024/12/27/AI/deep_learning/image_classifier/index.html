<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Images Classifier - BlackCrystal</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="“#2196f3”"><meta name="application-name" content="BlackCrystal"><meta name="msapplication-TileImage" content="icons/touch-icon-iphone.png"><meta name="msapplication-TileColor" content="“#2196f3”"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="BlackCrystal"><meta name="apple-mobile-web-app-status-bar-style" content="default"><link rel="apple-touch-icon" sizes="144x144" href="icons/touch-icon-iphone.png"><meta name="description" content="Classic networks like LeNet-5, AlexNet and VGG; Architectures like ResNet and Inception Net to improve performance of CNNs;  MobileNets to allow mobile devices to run apps of classifier systems;  Tra"><meta property="og:type" content="blog"><meta property="og:title" content="Images Classifier"><meta property="og:url" content="https://justinqy.github.io/2024/12/27/AI/deep_learning/image_classifier/"><meta property="og:site_name" content="BlackCrystal"><meta property="og:description" content="Classic networks like LeNet-5, AlexNet and VGG; Architectures like ResNet and Inception Net to improve performance of CNNs;  MobileNets to allow mobile devices to run apps of classifier systems;  Tra"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://justinqy.github.io/img/computer_vision_1.jpeg"><meta property="article:published_time" content="2024-12-27T17:53:13.000Z"><meta property="article:modified_time" content="2025-01-27T15:57:26.163Z"><meta property="article:author" content="JustinQYB"><meta property="article:tag" content="Computer Vision"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://justinqy.github.io/img/computer_vision_1.jpeg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://justinqy.github.io/2024/12/27/AI/deep_learning/image_classifier/"},"headline":"Images Classifier","image":[],"datePublished":"2024-12-27T17:53:13.000Z","dateModified":"2025-01-27T15:57:26.163Z","author":{"@type":"Person","name":"JustinQYB"},"publisher":{"@type":"Organization","name":"BlackCrystal","logo":{"@type":"ImageObject","url":{"text":"⭐️ Programming Saves the World ⭐️"}}},"description":"Classic networks like LeNet-5, AlexNet and VGG; Architectures like ResNet and Inception Net to improve performance of CNNs;  MobileNets to allow mobile devices to run apps of classifier systems;  Tra"}</script><link rel="canonical" href="https://justinqy.github.io/2024/12/27/AI/deep_learning/image_classifier/"><link rel="icon" href="/img/kitty_man.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link data-pjax rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link data-pjax rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><meta name="follow.it-verification-code" content="q0T4H8K7eaKT9rLkC1Kh"><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="BlackCrystal" type="application/atom+xml">
</head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">⭐️ Programming Saves the World ⭐️</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">TimeLine</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a></div><div class="navbar-end"><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="fill" src="/img/computer_vision_1.jpeg" alt="Images Classifier"></span></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-12-27T17:53:13.000Z" title="12/27/2024, 12:53:13 PM">2024-12-27</time></span><span class="level-item"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a><span> / </span><a class="link-muted" href="/categories/Deep-Learning/Supervised-Learning/">Supervised Learning</a><span> / </span><a class="link-muted" href="/categories/Deep-Learning/Supervised-Learning/CV/">CV</a><span> / </span><a class="link-muted" href="/categories/Deep-Learning/Supervised-Learning/CV/Image-Classify/">Image Classify</a></span></div></div><h1 class="title is-3 is-size-4-mobile">Images Classifier</h1><div class="content"><ol>
<li>Classic networks like LeNet-5, AlexNet and VGG;</li>
<li>Architectures like ResNet and Inception Net to improve performance of CNNs; </li>
<li>MobileNets to allow mobile devices to run apps of classifier systems; </li>
<li>Transfer Learning and Data Augmentation to start your system faster and make your classifier stronger.<span id="more"></span></li>
</ol>
<br/>

<h2 id="Classic-Networks"><a href="#Classic-Networks" class="headerlink" title="Classic Networks"></a><strong>Classic Networks</strong></h2><h3 id="LeNet-5"><a href="#LeNet-5" class="headerlink" title="LeNet-5"></a><strong>LeNet-5</strong></h3><hr>
<h4 id="Used"><a href="#Used" class="headerlink" title="Used"></a><strong>Used</strong></h4><p>Classify hand-write digit</p>
<h4 id="Trained"><a href="#Trained" class="headerlink" title="Trained"></a><strong>Trained</strong></h4><p>Gray scale images (32 * 32 * 1)</p>
<h4 id="Params"><a href="#Params" class="headerlink" title="Params"></a><strong>Params</strong></h4><p>60k</p>
<h4 id="Paper"><a href="#Paper" class="headerlink" title="Paper"></a><strong>Paper</strong></h4><p>Gradient-based learning applied to document recognition (part II)</p>
<h4 id="Feature"><a href="#Feature" class="headerlink" title="Feature"></a><strong>Feature</strong></h4><ol>
<li>as going deeper in the network, n_H, n_W goes down, n_C goes up</li>
<li>structure: conv-pool-conv-pool-fc-fc-output</li>
<li>using average pooling layers, and sigmoid&#x2F;tanh rather than ReLu functions in the hidden layers</li>
</ol>
<br/>

<h3 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a><strong>AlexNet</strong></h3><hr>
<h4 id="Used-1"><a href="#Used-1" class="headerlink" title="Used"></a><strong>Used</strong></h4><p>Image Recognition</p>
<h4 id="Trained-1"><a href="#Trained-1" class="headerlink" title="Trained"></a><strong>Trained</strong></h4><p>RGM images (227<em>227</em>3)</p>
<h4 id="Params-1"><a href="#Params-1" class="headerlink" title="Params"></a><strong>Params</strong></h4><p>60m </p>
<h4 id="Paper-1"><a href="#Paper-1" class="headerlink" title="Paper"></a><strong>Paper</strong></h4><p>ImageNet classification with deep convolutional neural networks</p>
<h4 id="Feature-1"><a href="#Feature-1" class="headerlink" title="Feature"></a><strong>Feature</strong></h4><ol>
<li>using ReLu function</li>
<li>multiple GPUs (GPU communicate with each other)</li>
<li>Local Response Normalization (choose a position in a image and normalize every same position among all channels)</li>
</ol>
<br/>

<h3 id="VGG-16"><a href="#VGG-16" class="headerlink" title="VGG - 16"></a><strong>VGG - 16</strong></h3><hr>
<h4 id="Used-2"><a href="#Used-2" class="headerlink" title="Used"></a><strong>Used</strong></h4><h4 id="Trained-2"><a href="#Trained-2" class="headerlink" title="Trained"></a><strong>Trained</strong></h4><p>RGM images (224<em>224</em>3)</p>
<h4 id="Params-2"><a href="#Params-2" class="headerlink" title="Params"></a><strong>Params</strong></h4><p>138m</p>
<h4 id="Paper-2"><a href="#Paper-2" class="headerlink" title="Paper"></a><strong>Paper</strong></h4><p>Very deep convolutional networks for large-scale image recognition</p>
<h4 id="Feature-2"><a href="#Feature-2" class="headerlink" title="Feature"></a><strong>Feature</strong></h4><ol>
<li>fixed filters: CONV &#x3D; 3 * 3 filter, s &#x3D; 1, same convolution; Max-Pool &#x3D; 2 * 2, s &#x3D; 2</li>
<li>the n_H and n_W shrink double (after every pool layer) or n_C grows double (after every conv layer)</li>
</ol>
<br/>

<h3 id="Residual-Network"><a href="#Residual-Network" class="headerlink" title="Residual Network"></a><strong>Residual Network</strong></h3><hr>
<p>For very deep networks, there are usually problems like gradient vanishing and gradient explosion.</p>
<p>With ResNets, we can train very deep networks.</p>
<h4 id="Residual-Block"><a href="#Residual-Block" class="headerlink" title="Residual Block"></a><strong>Residual Block</strong></h4><ol>
<li>A residual block contains some <em>extra layers</em> and a <em>skip connection</em>. (for example below, 2 fully-connected layers and 1 skip connection)</li>
<li>A <em>residual network</em> is a neural network contains <em>multiple residual blocks</em>.</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a[l] ---&gt; Linear ---&gt; ReLu ---&gt; a[l+<span class="number">1</span>] ---&gt; Linear ---&gt; ReLu ---&gt; a[l+<span class="number">2</span>]  (main path)</span><br><span class="line">      |                                             ^</span><br><span class="line">      |                                             | <span class="keyword">pass</span> <span class="string">&#x27;a[l]&#x27;</span> here before ReLu</span><br><span class="line">      ---------skip connection / short cut-----------</span><br><span class="line"></span><br><span class="line">Before: a[l+<span class="number">2</span>] = g(z[l+<span class="number">2</span>)</span><br><span class="line">After Adding Residual Block: a[l+<span class="number">2</span>] = g(z[l+<span class="number">2</span>] + a[l])</span><br></pre></td></tr></table></figure>

<h4 id="Paper-3"><a href="#Paper-3" class="headerlink" title="Paper"></a><strong>Paper</strong></h4><p>Deep residual networks for image recognition</p>
<h4 id="Features"><a href="#Features" class="headerlink" title="Features"></a><strong>Features</strong></h4><ol>
<li>compared to plain networks, ResNet allows us to have a reasonable training error even we have many layers.</li>
<li>Identity function is easy for Residual Block to learn. (That’s why adding more layers to the network doesn’t hurt the performance)</li>
<li>usually use ‘same convolutions’ in ResNets to make a[l] and z[l+2] have the same dimension. (If not, add an extra matrix ‘Ws’ to a[l])</li>
<li>we can turn a plain net into a res net by adding residual blocks.</li>
</ol>
<br/>

<h3 id="1-1-Convolutions-Network"><a href="#1-1-Convolutions-Network" class="headerlink" title="1*1 Convolutions Network"></a><strong>1*1 Convolutions Network</strong></h3><hr>
<p>one-by-one convolution is like having a <strong><em>fully-connect neural network</em></strong> that apply to each position of the input channels.</p>
<h4 id="Paper-4"><a href="#Paper-4" class="headerlink" title="Paper"></a><strong>Paper</strong></h4><p>Network in network</p>
<h4 id="Features-1"><a href="#Features-1" class="headerlink" title="Features"></a><strong>Features</strong></h4><ol>
<li>use one-by-one convolutions to <strong><em>shrink the number of volume</em></strong></li>
</ol>
<br/>

<h3 id="Inception-Network-‘Google-Net’-Inception-V1"><a href="#Inception-Network-‘Google-Net’-Inception-V1" class="headerlink" title="Inception Network (‘Google Net’: Inception V1)"></a><strong>Inception Network (‘Google Net’: Inception V1)</strong></h3><hr>
<p>In generally speaking: Instead of needing to pick any size of the filters or pooling, we do them all and concatenate all the outputs. Let the network learn whatever params it wants to use. </p>
<p>Inception Network: Neural network puts a lot of inception modules together.</p>
<h4 id="Paper-5"><a href="#Paper-5" class="headerlink" title="Paper"></a><strong>Paper</strong></h4><p>Going deeper with convolutions</p>
<h4 id="Inception-Module-inception-blocks"><a href="#Inception-Module-inception-blocks" class="headerlink" title="Inception Module (inception blocks)"></a><strong>Inception Module (inception blocks)</strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">                  --------------------------------&gt; <span class="number">1</span> * <span class="number">1</span> CONV ---------|</span><br><span class="line">                  |                                                     |</span><br><span class="line">Previous          |------------&gt; <span class="number">1</span> * <span class="number">1</span> CONV ------&gt; <span class="number">3</span> * <span class="number">3</span> CONV ---------|       Channel</span><br><span class="line">Activation  ------                                                      |----&gt;  Concat</span><br><span class="line">                  |------------&gt; <span class="number">1</span> * <span class="number">1</span> CONV ------&gt; <span class="number">5</span> * <span class="number">5</span> CONV ---------|</span><br><span class="line">                  |                                                     |</span><br><span class="line">                  ----------&gt; MaxPool(Padding) ---&gt; <span class="number">1</span> * <span class="number">1</span> CONV ---------|</span><br></pre></td></tr></table></figure>

<h4 id="Feature-3"><a href="#Feature-3" class="headerlink" title="Feature"></a><strong>Feature</strong></h4><ol>
<li>Computational Cost: Use 1*1 convolution to shrink the channel first, then do regular convolutions.</li>
<li>Have several side branches that also predict like the output layer (ends with a softmax function), this has a regularizing effect and reduces the overfitting.</li>
</ol>
<br/>

<h3 id="MobileNet-V1"><a href="#MobileNet-V1" class="headerlink" title="MobileNet V1"></a><strong>MobileNet V1</strong></h3><hr>
<h4 id="Depthwise-Separable-Convolution-Building-Block-of-MobileNets"><a href="#Depthwise-Separable-Convolution-Building-Block-of-MobileNets" class="headerlink" title="Depthwise Separable Convolution (Building Block of MobileNets)"></a><strong>Depthwise Separable Convolution <em>(Building Block of MobileNets)</em></strong></h4><h5 id="Depthwise-Convolution"><a href="#Depthwise-Convolution" class="headerlink" title="Depthwise Convolution"></a><strong>Depthwise Convolution</strong></h5><p>n_c filters, each filter(size: f * f * 1) convolve with each channel of input, the channel of output will be the same as input  </p>
<h5 id="Pointwise-Convolution-Projection"><a href="#Pointwise-Convolution-Projection" class="headerlink" title="Pointwise Convolution (Projection)"></a><strong>Pointwise Convolution <em>(Projection)</em></strong></h5><p>n_c’ filters, each filter(size: 1 * 1 * n_c) convolve with the whole input, the channel of output will be n_c’</p>
<h4 id="Paper-6"><a href="#Paper-6" class="headerlink" title="Paper"></a><strong>Paper</strong></h4><p>MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications</p>
<h4 id="Feature-4"><a href="#Feature-4" class="headerlink" title="Feature"></a><strong>Feature</strong></h4><ol>
<li>Low computational cost at deployment: MobileNets cost usually $\frac{1}{n_c’} + \frac{1}{f * f}$ times of that in normal convolutions, which is about 10 times cheaper.</li>
<li>Useful for mobile and embedded vision applications</li>
</ol>
<br/>

<h3 id="MobileNet-V2"><a href="#MobileNet-V2" class="headerlink" title="MobileNet V2"></a><strong>MobileNet V2</strong></h3><hr>
<h4 id="Paper-7"><a href="#Paper-7" class="headerlink" title="Paper"></a><strong>Paper</strong></h4><p>MobileNetV2: Inverted Residuals and Linear Bottlenecks</p>
<h4 id="Bottleneck-Block"><a href="#Bottleneck-Block" class="headerlink" title="Bottleneck Block"></a><strong>Bottleneck Block</strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">    --------------------------------- Residual Connection -------------------------------</span><br><span class="line">    |                                                                                   |</span><br><span class="line">    |           (channel expands)                         (channel shrinks)             v</span><br><span class="line">--------&gt; n * n * <span class="number">3</span> --------&gt; n * n * <span class="number">18</span> --------&gt; n * n * <span class="number">18</span> ----------&gt; n * n * <span class="number">3</span> ---------&gt;</span><br><span class="line">                        ^                    ^                     ^</span><br><span class="line">                        |                    |                     |</span><br><span class="line">                    <span class="number">1</span> * <span class="number">1</span> * <span class="number">3</span>            Depthwise             <span class="number">1</span> * <span class="number">1</span> * <span class="number">18</span></span><br><span class="line">                    Expansion        (same convolution)        Pointwise/Projection</span><br><span class="line">                   (<span class="number">18</span> filters)         (<span class="number">18</span> filters)           (<span class="number">3</span> filters)</span><br></pre></td></tr></table></figure>

<h4 id="Why-using-Bottle-Block"><a href="#Why-using-Bottle-Block" class="headerlink" title="Why using Bottle Block?"></a><strong>Why using Bottle Block?</strong></h4><ol>
<li>By using ‘Expansion’, it lets the neural network to learn a richer function by increasing the representation. (From n * n * 3 to n * n * 18)</li>
<li>Memory is limited for mobile devices, so bottleneck block uses ‘Pointwise&#x2F;Projection’ operation to shrink the representation before pass it to next block. (When passing, the memory needs to pass these values reduced.)</li>
</ol>
<br/>

<h3 id="EfficientNet"><a href="#EfficientNet" class="headerlink" title="EfficientNet"></a><strong>EfficientNet</strong></h3><hr>
<p>How to automatically increase or scale the size of the neural network on different devices?</p>
<p>‘<em>Good Trades off</em>‘ between image resolution, depth of the network and width of the layers.</p>
<h4 id="Paper-8"><a href="#Paper-8" class="headerlink" title="Paper"></a><strong>Paper</strong></h4><p>EfficientNet: Rethinking Model Scaling for Convolutional Neural Network</p>
<br/>

<h3 id="Transfer-Learning"><a href="#Transfer-Learning" class="headerlink" title="Transfer Learning"></a><strong>Transfer Learning</strong></h3><hr>
<p>How to create a classifier for myself if I don’t have much data? Using Transfer Learning!</p>
<p>In Computer Vision, transfer learning is one thing that you should almost always do.(Unless you have an exceptionally large data set)</p>
<h4 id="Freeze-Layers"><a href="#Freeze-Layers" class="headerlink" title="Freeze Layers"></a><strong>Freeze Layers</strong></h4><h5 id="When-you-have-Little-Data"><a href="#When-you-have-Little-Data" class="headerlink" title="When you have Little Data"></a><strong>When you have Little Data</strong></h5><ol>
<li>Download a open-sourced implementation of neural network(with its weights), <strong>replace the softmax and output</strong> layer with your own layers and <strong><em>freeze the other layers</em></strong>.</li>
<li><em>Train your own ‘softmax’ and ‘output’ layers.</em></li>
</ol>
<h5 id="When-you-have-Large-Data"><a href="#When-you-have-Large-Data" class="headerlink" title="When you have Large Data"></a><strong>When you have Large Data</strong></h5><p><em>Freeze fewer</em> layers and <em>train the later</em> layers (Initialize the weights of later layers and run gradient descent on them. &#x2F; Blow away these layers and create you own layers.).</p>
<h5 id="When-you-have-A-Lot-of-Data"><a href="#When-you-have-A-Lot-of-Data" class="headerlink" title="When you have A Lot of Data"></a><strong>When you have A Lot of Data</strong></h5><p><em>Change the ‘softmax’ and ‘output’</em> layers, and <em>train the whole</em> network.</p>
<h5 id="Neat-Trick-to-Speed-up-Training"><a href="#Neat-Trick-to-Speed-up-Training" class="headerlink" title="Neat Trick to Speed up Training"></a><strong>Neat Trick to Speed up Training</strong></h5><p>Since you froze several layers and didn’t want to train them: <strong><em>pre-compute the last frozen layer for all training sets and save the results to disk</em></strong>. </p>
<p>So you just need to train a shallow softmax classifier instead of a big one.</p>
<p>Fast Reason: You don’t need to calculate the frozen layers <strong>everytime</strong> you train the network.</p>
<br/>

<h3 id="Data-Augmentation"><a href="#Data-Augmentation" class="headerlink" title="Data Augmentation"></a><strong>Data Augmentation</strong></h3><hr>
<h4 id="Common-augmentation-methods-distortions"><a href="#Common-augmentation-methods-distortions" class="headerlink" title="Common augmentation methods (distortions)"></a><strong>Common augmentation methods (distortions)</strong></h4><ol>
<li>Mirroring</li>
<li>Random Cropping</li>
<li>Color shifting: Add different distortions to RGB channels. (color distortion algorithm: PCA Color Augmentation-Principles Component Analysis)</li>
</ol>
<h4 id="Less-using-methods"><a href="#Less-using-methods" class="headerlink" title="Less using methods"></a><strong>Less using methods</strong></h4><ol>
<li>Rotation</li>
<li>Shearing</li>
<li>Local warping</li>
</ol>
<h4 id="Hyper-params-in-Data-Augmentation"><a href="#Hyper-params-in-Data-Augmentation" class="headerlink" title="Hyper params in Data Augmentation"></a><strong>Hyper params in Data Augmentation</strong></h4><p>A good way is to use others’ trained hyper params in their network.</p>
<h4 id="Implementing-Distortions"><a href="#Implementing-Distortions" class="headerlink" title="Implementing Distortions"></a><strong>Implementing Distortions</strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">implementing distortions during training:</span><br><span class="line"></span><br><span class="line">                                  distortions</span><br><span class="line">hard disk           ----- data1 -------&gt;-------- new data1 ------          </span><br><span class="line">  ----             |                                             |</span><br><span class="line">  |  |  --- load ---                                             ---------&gt; Training</span><br><span class="line">  ----             |              distortions                    |   </span><br><span class="line">                    ----- data2 -------&gt;-------- new data2 ------            CPU/GPU --------</span><br><span class="line">                                                                                             |----&gt; can run <span class="keyword">in</span> parallel</span><br><span class="line">                                    CPU threads  --------------------------------------------</span><br><span class="line">                     (loading data <span class="keyword">and</span> implementing distortions)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<br/>

<h3 id="Tips-for-Benchmarks-and-Competitions"><a href="#Tips-for-Benchmarks-and-Competitions" class="headerlink" title="Tips for Benchmarks and Competitions"></a><strong>Tips for Benchmarks and Competitions</strong></h3><hr>
<ol>
<li><strong>Ensembling</strong> (<em>maybe 1% or 2% better, needs much memory</em>): Train several networks independently and average their outputs.(like ‘tree ensemble’)</li>
<li><strong>Multi-crop at test time</strong> (<em>a little bit better, don’t need much memory</em>): Run classifier on multiple versions of test images and average results. (10-crop)</li>
</ol>
<br/>

<h3 id="Tips-for-Building-a-Computer-Vision-Practical-System"><a href="#Tips-for-Building-a-Computer-Vision-Practical-System" class="headerlink" title="Tips for Building a Computer Vision Practical System"></a><strong>Tips for Building a Computer Vision Practical System</strong></h3><hr>
<ol>
<li>Use architectures of networks published in the literature.</li>
<li>Use open source implementation if possible.</li>
<li>Use pretrained models and fine-tune on your dataset.</li>
<li>If you have huge data or need to invent a system by yourself, you can make a system from scratch.</li>
</ol>
<br/>

<p><strong>Reference</strong></p>
<ol>
<li><a target="_blank" rel="noopener" href="https://www.coursera.org/learn/convolutional-neural-networks/home/week/2">https://www.coursera.org/learn/convolutional-neural-networks/home/week/2</a></li>
</ol>
</div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/Computer-Vision/">Computer Vision</a></div><!--!--></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">Like this article? Support the author with</h3><div class="buttons is-centered"><a class="button donate" href="/img/coffee.jpg" target="_blank" rel="noopener" data-type="buymeacoffee"><span class="icon is-small"><i class="fas fa-coffee"></i></span><span>Buy me a coffee</span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2025/01/03/AI/deep_learning/object_detection/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Object Detection</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2024/12/15/AI/deep_learning/convolutional_neural_network/"><span class="level-item">Convolutional Neural Network</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'https://justinqy.github.io/2024/12/27/AI/deep_learning/image_classifier/';
            this.page.identifier = '2024/12/27/AI/deep_learning/image_classifier/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'blackcrystal-1' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/cat1.jpg" alt="Yibo Qiao"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Yibo Qiao</p><p class="is-size-6 is-block">MEng student in McMaster</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Hamilton, ON, Canada</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">40</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">32</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">10</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/JustinQY" target="_blank" rel="me noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="Github" href="https://github.com/JustinQY"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="Linkedin" href="https://www.linkedin.com/in/qiaoy1999"><i class="fab fa-linkedin"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="RSS" href="https://justinqy.github.io/atom.xml"><i class="fas fa-rss"></i></a></div><div class="level is-mobile is-multiline"><iframe frameborder="no" border="5" marginwidth="0" marginheight="0" width="100%" height="86" src="//music.163.com/outchain/player?type=2&amp;id=64638&amp;auto=0&amp;height=66"></iframe></div></div></div><!--!--><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/CNN/"><span class="tag">CNN</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Computer-Vision/"><span class="tag">Computer Vision</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Interviews/"><span class="tag">Interviews</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Kaggle/"><span class="tag">Kaggle</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ML/"><span class="tag">ML</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Neural-Network/"><span class="tag">Neural Network</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Python/"><span class="tag">Python</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Todo/"><span class="tag">Todo</span></a></div><div class="control"><a class="tags has-addons" href="/tags/iOS/"><span class="tag">iOS</span></a></div><div class="control"><a class="tags has-addons" href="/tags/markdown/"><span class="tag">markdown</span></a></div></div></div></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2025/01/"><span class="level-start"><span class="level-item">January 2025</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/12/"><span class="level-start"><span class="level-item">December 2024</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/10/"><span class="level-start"><span class="level-item">October 2024</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/07/"><span class="level-start"><span class="level-item">July 2024</span></span><span class="level-end"><span class="level-item tag">22</span></span></a></li></ul></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="https://api.follow.it/subscription-form/U0hMNnFsTU5wa1h0NWsxSXNQM09YZlFjM1BScCtkQ1lPeFp6eXRxeFJhcXZpbEJ3SldtMFg3eE1zYXpXa2hiYXBIM3FXdmdGNjRYZkw3OXBsSmR2RTdDTHgxMmRscnFsL0FzYUJpaVpwSHVJemx0TUZKT2U2ZjlzM2FCdm14K1h8QUErOXVROGVMRzhrVFBkNVVRbHdMM0hFZmhoSEx1YzU3bTVuNmxwYnkrdz0=/8" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Deep-Learning/"><span class="level-start"><span class="level-item">Deep Learning</span></span><span class="level-end"><span class="level-item tag">7</span></span></a><ul><li><a class="level is-mobile" href="/categories/Deep-Learning/Supervised-Learning/"><span class="level-start"><span class="level-item">Supervised Learning</span></span><span class="level-end"><span class="level-item tag">7</span></span></a><ul><li><a class="level is-mobile" href="/categories/Deep-Learning/Supervised-Learning/CNN/"><span class="level-start"><span class="level-item">CNN</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Deep-Learning/Supervised-Learning/CV/"><span class="level-start"><span class="level-item">CV</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/Deep-Learning/Supervised-Learning/CV/Face-Recognition/"><span class="level-start"><span class="level-item">Face Recognition</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Deep-Learning/Supervised-Learning/CV/Image-Classify/"><span class="level-start"><span class="level-item">Image Classify</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Deep-Learning/Supervised-Learning/CV/Neural-Style-Transfer/"><span class="level-start"><span class="level-item">Neural Style Transfer</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Deep-Learning/Supervised-Learning/CV/Object-Detection/"><span class="level-start"><span class="level-item">Object Detection</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Deep-Learning/Supervised-Learning/Standard-Neural-Network/"><span class="level-start"><span class="level-item">Standard Neural Network</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="/categories/Kaggle/"><span class="level-start"><span class="level-item">Kaggle</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Machine-Learning/"><span class="level-start"><span class="level-item">Machine Learning</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/Machine-Learning/Supervised-Learning/"><span class="level-start"><span class="level-item">Supervised Learning</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/Machine-Learning/Supervised-Learning/Linear-Regression/"><span class="level-start"><span class="level-item">Linear Regression</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Machine-Learning/Supervised-Learning/Logistic-Regression/"><span class="level-start"><span class="level-item">Logistic Regression</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Machine-Learning/Supervised-Learning/Model-Optimization/"><span class="level-start"><span class="level-item">Model Optimization</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="/categories/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">9</span></span></a><ul><li><a class="level is-mobile" href="/categories/Python/Basic/"><span class="level-start"><span class="level-item">Basic</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Math/"><span class="level-start"><span class="level-item">Math</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Model/"><span class="level-start"><span class="level-item">Model</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Numpy/"><span class="level-start"><span class="level-item">Numpy</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Pandas/"><span class="level-start"><span class="level-item">Pandas</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Plot/"><span class="level-start"><span class="level-item">Plot</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Scikit-Learn/"><span class="level-start"><span class="level-item">Scikit Learn</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/Venv/"><span class="level-start"><span class="level-item">Venv</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Todo/"><span class="level-start"><span class="level-item">Todo</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/iOS/"><span class="level-start"><span class="level-item">iOS</span></span><span class="level-end"><span class="level-item tag">15</span></span></a><ul><li><a class="level is-mobile" href="/categories/iOS/Objective-C/"><span class="level-start"><span class="level-item">Objective-C</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/iOS/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"><span class="level-start"><span class="level-item">内存管理</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/iOS/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"><span class="level-start"><span class="level-item">多线程</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/iOS/%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/"><span class="level-start"><span class="level-item">第三方库</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/iOS/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"><span class="level-start"><span class="level-item">设计模式</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/markdown/"><span class="level-start"><span class="level-item">markdown</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-01-27T15:47:41.000Z">2025-01-27</time></p><p class="title"><a href="/2025/01/27/python/math/">math</a></p><p class="categories"><a href="/categories/Python/">Python</a> / <a href="/categories/Python/Math/">Math</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-01-27T15:41:37.000Z">2025-01-27</time></p><p class="title"><a href="/2025/01/27/python/tensorflow_pytorch/">Tensorflow And Pytorch</a></p><p class="categories"><a href="/categories/Python/">Python</a> / <a href="/categories/Python/Model/">Model</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-01-27T15:41:06.000Z">2025-01-27</time></p><p class="title"><a href="/2025/01/27/python/plotting/">Plotting Data</a></p><p class="categories"><a href="/categories/Python/">Python</a> / <a href="/categories/Python/Plot/">Plot</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-01-27T15:40:54.000Z">2025-01-27</time></p><p class="title"><a href="/2025/01/27/python/pandas/">Pandas</a></p><p class="categories"><a href="/categories/Python/">Python</a> / <a href="/categories/Python/Pandas/">Pandas</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-01-27T15:40:42.000Z">2025-01-27</time></p><p class="title"><a href="/2025/01/27/python/numpy/">Numpy</a></p><p class="categories"><a href="/categories/Python/">Python</a> / <a href="/categories/Python/Numpy/">Numpy</a></p></div></article></div></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://flipped895.github.io/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">flipped</span></span><span class="level-right"><span class="level-item tag">flipped895.github.io</span></span></a></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">⭐️ Programming Saves the World ⭐️</a><p class="is-size-7"><span>&copy; 2025 JustinQYB</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p><p class="is-size-7">© 2019</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script data-pjax src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script data-pjax src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/mhchem.min.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/javascript" id="MathJax-script" async>MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      svg: {
        fontCache: 'global'
      },
      chtml: {
        matchFontHeight: false
      }
    };</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js"></script><!--!--><!--!--><!--!--><script data-pjax src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script data-pjax src="/js/insight.js" defer></script><script data-pjax>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script><script defer type="text/javascript" color="220,220,220" opacity="0.5" zIndex="-1" count="200" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":200,"height":350},"mobile":{"show":true},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>