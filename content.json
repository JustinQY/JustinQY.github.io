{"posts":[{"title":"iOS MJExtension","text":"MJExtension MJExtension – Json转Model一. Json数据定义：JSON(JavaScript Object Notation) 是一种轻量级的数据交换格式。JSON采用完全独立于语言的文本格式，这些特性使JSON成为理想的数据交换语言。易于人阅读和编写，同时也易于机器解析和生成。 —– Json可以将js对象中表示的一组数据转换为字符串，然后就可以在函数之间传递这个字符串，且js很容易解析它。 基础结构： “名称/值”对的集合（A collection of name/value pairs）。不同的语言中，它被理解为对象（object），记录（record），结构（struct），字典（dictionary），哈希表（hash table），有键列表（keyed list），或者关联数组 （associative array）。 值的有序列表（An ordered list of values）。在大部分语言中，它被理解为数组（array）。 实例： 名称/值 {“firstName”:”Mary”, “lastName”:”Frank”, “email”:”gmail”} 表示数组 { “people”: [ { “firstName”: “Brett”, “lastName”:”McLaughlin”, “email”: “aaaa” }, { “firstName”: “Jason”, “lastName”:”Hunter”, “email”: “bbbb”}, { “firstName”: “Elliotte”, “lastName”:”Harold”, “email”: “cccc” } ]} 特点： Json是完全动态的，允许在Json结构中改变表示数据的方式 二. MJExtension的使用","link":"/2024/07/04/iOS/iOS_MJExtension/"},{"title":"iOS之MRC与ARC","text":"MRC &amp; ARC 内存管理模型一. 需要进行内存管理的对象 任何继承了NSObject的对象需要进行内存管理 非对象类型(int、char、float、double、struct、enum等) 不需要进行内存管理 二. 内存结构1. 堆一般由程序员分配释放，若程序员不释放，程序结束时可能由OS回收，分配方式类似于链表，继承了NSObject的对象存储在堆中。 2. 栈由操作系统自动分配释放，存放函数的参数值，局部变量的值等，分配方式类似于栈。 3. 数据段（data区）4. 代码段（text区）三. OC内存管理模型1. 自动垃圾收集（iOS运行环境不支持）2. 手动引用计数（MRC）和自动释放池（AutoReleasePool）3. 自动引用计数（ARC）四. MRC &amp; AutoReleasePool – 手动引用计数与自动释放池1. 引用计数器引用计数器是一个整数，即对象被引用的次数。系统根据对象的引用计数器判断何时应该回收它所占用的内存。每个OC对象都有自己的引用计数器，任何对象刚创建的时候，引用计数器为1。 2. 引用计数器的操作 每当创建引用到对象需要给对象发送一条retain消息，此时该对象引用计数器值**+1。** 每当不需要该对象时给对象发送一条release消息，此时该对象引用计数器值**-1** 给对象发送retainCount消息，可以获得当前对象引用计数器值。 当对象的引用计数器值为0时，系统通过给该对象发送dealloc消息，释放该对象的内存。 3. dealloc 对象即将被销毁时系统会自动给对象发送一条dealloc消息。 一般会重写dealloc方法，即在这里释放相关资源，该方法一旦重写，必须在方法最后调用**[super dealloc]**。 不能直接调用dealloc方法。 4. 野指针和空指针 当一个指针指向一个“僵尸对象”（被释放了的对象），这个指针就是野指针。 为避免给野指针发送消息报错，在它指向的对象被释放后，将它设置为空指针（没有指向存储空间的指针）。 5. 自动释放池 – AutoReleasePool autorelease是一种支持引用计数的内存管理方式，给对象发送一条autorelease信息，会将对象放到一个自动释放池中，当自动释放池被销毁时，会对池子中的所有对象发送一次release消息（只是发送release消息，并不是将对象直接释放）。 autorelease方法会返回对象本身，其实质上是延迟了给对象发送release消息的操作。 NSAutoreleasePool *pool创建等同与@autoreleasepool创建，前者需要调用 [pool drain]来销毁自动释放池。 自动释放池中不适宜放占用内存较大的对象或大量循环操作。 6. 循环retain 当A对象要拥有B对象，同时B对象要拥有A对象，此时会形成循环retain，导致A和B对象永远无法释放。 尽量避免双端互相引用，或者一端用retain，一端用assign。 五. ARC – 自动引用计数1. ARC自动引用计数，系统检测出何时需要保持对象，何时需要自动释放对象，编译器会管理内存，并在合适的地方加入retain，release和autorelease。 2. ARC的判断原则 – 强指针 ARC通过强指针判断一个对象是否需要释放。 默认所有对象的指针变量都是强指针，或者被“__strong”修饰的指针。 被**__weak修饰的指针是弱指针**。 只要还有一个强指针变量指向对象，对象就会保持在内存中。 3. ARC的注意事项 不能调用对象的release方法。 不能调用autorelease方法。 重写dealloc方法时，不能调用**[super dealloc]**。 4. 单对象内存管理 局部变量（局部强指针）超出作用域释放，对象随之被释放。 清空指针（默认清空的所有指针都是强指针），对象随之被释放。 弱指针保存新创建的对象时，对象会立即被释放。 5. 多对象内存管理 想要拥有某个对象必须使用强指针保存它，无需在dealloc方法中release。 6. property参数 strong：用于OC对象，相当于MRC中的retain。 weak：用于OC对象，相当于MRC中的assign。 assign：用于基本数据类型，与MRC中的assign相同。 7. 循环引用如果A拥有B，B也拥有A，那么其中一方必须使用弱指针。","link":"/2024/07/04/iOS/iOS_MRC%E4%B8%8EARC/"},{"title":"NSThread","text":"NSthread记录~~~ 创建子线程 123456789101112131415161718192021222324252627282930313233343536373839//线程创建方法1 -- allo + init- (void)createThread1 { /* 第一个参数：目标对象 self 第二个参数：方法选择器 -&gt; 调用的方法 第三个参数：前面调用的方法需要传递的参数 -&gt; nil */ NSThread *thread = [[NSThread alloc] initWithTarget:self selector:@selector(run:) object:@&quot;test&quot;]; //启动线程 [thread start]; //设置线程属性 thread.name = @&quot;线程A&quot;; [thread setName:@&quot;线程A&quot;]; //设置线程优先级 -- 优先级大小(0.0 ~ 1.0), 默认为0.5 thread.threadPriority = 1.0; //线程生命周期 -- 当任务执行完成之后被释放}//线程创建方法2 -- 无法获取创建的线程对象- (void)createThread2 { //分离子线程方法 [NSThread detachNewThreadSelector:@selector(run:) toTarget:self withObject:@&quot;通过分离子线程创建新线程&quot;];}//线程创建方法3-- 无法获取创建的线程对象- (void)createThread3 { //开启后台线程方法 [self performSelectorInBackground:@selector(run:) withObject:@&quot;通过开启后台线程创建新线程&quot;];}- (void)test:(NSString *)para { NSLog(@&quot;-----test-----%@&quot;, [NSThread currentThread]);} 子线程状态切换 12345678910111213141516171819- (void)createThread1 { //新建状态 NSThread *thread = [[NSThread alloc] initWithTarget:self selector:@selector(run:) object:@&quot;test&quot;]; //就绪或运行状态 [thread start];}- (void)test:(NSString *)para { NSLog(@&quot;-----test-----%@&quot;, [NSThread currentThread]); //阻塞状态 [NSThread sleepFortimeinterval:2.0]; [NSThread sleepUntilDate:[NSDate dateWithTimeIntervalSinceNow:3.0]]; //死亡状态 [NSThread exit];} 线程间通信实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950//网络图片下载Demo -- NSThread实现#import &quot;ViewController.h&quot;@interface ViewController ()@property(nonatomic, strong) UIImageView *imageView;@property(nonatomic, strong) NSThread *threadA;@end@implementation ViewController//耗时操作要用子线程进行- (void)touchesBegan:(NSSet&lt;UITouch *&gt; *)touches withEvent:(UIEvent *)event { //分离一条子线程去执行download方法 [NSThread detachNewThreadSelector:@selector(download) toTarget:self withObject:nil];}- (void)download { //确定图片URL NSURL *url = [NSURL URLWithString:@&quot;https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fa1.att.hudong.com%2F62%2F02%2F01300542526392139955025309984.jpg&amp;refer=http%3A%2F%2Fa1.att.hudong.com&amp;app=2002&amp;size=f9999,10000&amp;q=a80&amp;n=0&amp;g=0n&amp;fmt=jpeg?sec=1613890070&amp;t=9b041b83f4ddfe8c165547120f5aa589&quot;]; //根据URL下载图片二进制数据到本地 NSData *imageData = [NSData dataWithContentsOfURL:url]; //图片格式转换 UIImage *image = [UIImage imageWithData:imageData]; //回到主线程显示UI的三种方法 //方法1 /* 参数1：回到主线程要调用的方法 参数2：前面方法需要的参数 参数3：当前方法剩余部分的执行是否等待参数1方法执行完毕 */ [self performSelectorOnMainThread:@selector(showImage:) withObject:image waitUntilDone:YES]; //方法2 -- 主动选择执行线程为主线程 [self performSelector:@selector(showImage:) onThread:[NSThread mainThread] withObject:image waitUntilDone:YES]; //方法3 -- 直接用self.imageView调用主线程方法 [self.imageView performSelectorOnMainThread:@selector(setImage:) withObject:image waitUntilDone:YES]; }- (void)showImage:(UIImage *)image { self.imageView.image = image;}@end","link":"/2024/07/03/iOS/iOS_NSThread/"},{"title":"ObjectiveC 小记","text":"记录一些Objective-C的使用技巧和注意事项, 也算是对iOS开发生涯的总结~~~(in progress) 面向对象思想 面向对象和面向过程的区别 面向过程强调功能行为，关注解决问题需要哪些步骤 (所有过程亲力亲为) 面向对象将功能封装进对象，强调具备了功能的对象，关注的是解决问题需要哪些对象 (找到具有对应功能的对象，让对象去做事情) 面向对象思想在完成需求中的运用先去找具有所需功能的对象来用, 如果该对象那个不存在，那么创建一个具有该功能的对象 类与对象对象是由类创建的，因此应先考虑设计哪些类，再考虑用类创建哪些对象 类的设计描述一个类，主要描述该类的属性和行为，即成员变量和成员方法 类的分析 一般名词都是类 拥有类似属性和行为的对象可以抽象成一个类 OC中类的本质是一个结构体 类的声明 类的声明以@interface开头，以@end结尾，写上类名和继承的类，类名首字母大写，告诉系统类中有哪些属性和行为 OC类声明中属性只能写在interface和end中的大括号中，建议将属性名称前面都加上 “_” 类的实现 以@implement开头，以@end结尾 类中方法的实现 对象的创建 用类创建对象，必须给类发送一个消息 如何发送消息 [类名称/对象名称 方法名称] 发送什么消息 new 用什么保存新创建的对象 指针 对象方法 减号开头 只能由对象调用 类方法 加号开头 只能由类，即用类名调用 某个功能经常被使用，避免每次为了使用该方法而开辟新对象浪费存储空间，可将它声明为类方法 注意事项 OC中的”（）“是专门用来扩住数据类型的， 如 - (int)signal:(int) number; 类方法和对象方法的区别 对象方法必须由对象调用，类方法必须由类调用 类方法中不能直接访问该类的属性变量，对象方法可以直接访问类的属性变量 类方法的调用效率会比调用对象方法高 类方法和对象方法可以相互调用 对象方法中可以直接调用类方法 类方法中可以直接调用对象方法 类方法中可以直接调用类方法 对象方法中可以直接调用对象方法 主头文件 &lt;Foundation/Foundation.h&gt; 主头文件中拷贝了该工具箱中所有工具的头文件，只需导入主头文件就可使用该工具箱中所有的工具，避免每次使用都要导入一个对应头文件。 OC是C语言的超集，相当于在C语言上增加了面向对象的部分，因此C语言程序，C++程序可以在OC项目中编译。 property参数 成员变量前加@property，系统会自动生成getter/setter方法 加上retain，系统自动生成getter/setter方法，但是需要重写dealloc方法 默认情况下是assign","link":"/2024/07/04/iOS/iOS_ObjectiveC%E5%B0%8F%E8%AE%B0/"},{"title":"UICollectionView学习笔记","text":"UICollectionView 学习UICollectionViewUICollectionView的组成 Cell – 用于展示内容，尺寸和内容可以各不相同。 Supplementary Views – 追加视图，类似于UITableView中每个Section的Header或Footer Decoration View – 装饰视图，跟数据无关，为Cell和Supplementary Views添加辅助视图。 所有的UICollectionView都有该三个部件组成 UICollectionView的实现 dataSource – 为View提供数据源，给View提供需要显示的数据&nbsp;&nbsp;&nbsp;方法：&nbsp;&nbsp;&nbsp;1). numberOfSectionsInCollectionView: &nbsp;–&nbsp; 获取section数量&nbsp;&nbsp;&nbsp;2). collectionView:numberOfItemsInSection: &nbsp;–&nbsp; 获取某个section中item的数量&nbsp;&nbsp;&nbsp;3). collectionView:cellForItemAtIndexPath: &nbsp;–&nbsp; 对于某个位置的cell是怎样的&nbsp;&nbsp;&nbsp;4). collectionView:viewForSupplementaryElementOfKind:atIndexPath: &nbsp;–&nbsp; 对于某个位置的section显示怎样的Supplementary View delegate – 负责实现与用户交互的相应，为样式实现一些细节 &nbsp; &nbsp; 交互举例: &nbsp;&nbsp;&nbsp;1).cell高亮 &nbsp;&nbsp;&nbsp;2).cell选中时的状态 &nbsp;&nbsp;&nbsp;3).长按后的菜单显示 &nbsp;&nbsp;&nbsp;监听cell点击：(当用户点击cell时触发的delegate询问) &lt;点击事件发生&gt; &nbsp;&nbsp;&nbsp; 1).-collectionView:shouldHighlightItemAtIndexPath:&nbsp;–&nbsp;是否应该高亮？ &nbsp;&nbsp;&nbsp; 2).-collectionView:didHighlightItemAtIndexPath:&nbsp;–&nbsp;确认显示高亮（如果1返回YES则执行，否则不执行） &lt;点击事件结束(手指抬起)&gt; &nbsp;&nbsp;&nbsp; 3).-collectionView:shouldSelectItemAtIndexPath:&nbsp;–&nbsp;是否应该选中被点击的cell(如果1返回NO这里不再询问询问是否选中) &nbsp;&nbsp;&nbsp; 4).-collectionView:didSelectItemAtIndexPath:&nbsp;–&nbsp;确认选中被点击的cell(如果3中返回选中，调用选中) &nbsp;&nbsp;&nbsp; 5).-collectionView:didUnhighlightItemAtIndexPath:&nbsp;–&nbsp;确认取消高亮(如果1返回YES，那么会调用取消高亮) UICollectionViewLayout – 为CollectionView定义一些独特的布局 UICollectionView子视图的复用UICollectionView中所有视图都来自一个可复用的基类 –&gt; UICollectionReusableView， 在UICollectionView中，对于cell，Supplementary View和Decoration View都是需要复用的。 UICollectionVIewCell的组成相比于UITableViewCell，UICollectionViewCell不存在style，没有titleLabel和内置的imageView属性1.cell &nbsp;&nbsp;&nbsp;–&nbsp;&nbsp;&nbsp; 在这里是UICollectionReusableView 2.backgroundvView &nbsp;&nbsp;&nbsp;–&nbsp;&nbsp;&nbsp; cell的背景视图，可以设置背景图片 3.selectedBackgroundView &nbsp;&nbsp;&nbsp;–&nbsp;&nbsp;&nbsp; cell被选中时的背景视图 4.contentView &nbsp;&nbsp;&nbsp;–&nbsp;&nbsp;&nbsp; 内容视图，自定义cell时将内容放在这个View上 布局 – UICollectionViewLayoutUICollectionViewLayout是UICollectionView特有的，可以将每个cell, Supplementary View和Decoration View进行组合，为它们设置各自的属性(位置，大小，透明度，层级关系，形状等)。它可以决定UICollectionView如何显示在界面上。 1.流水布局(线性布局) &nbsp;&nbsp;&nbsp;–&nbsp;&nbsp;&nbsp;UICollectionViewFlowLayout &nbsp;&nbsp;&nbsp;&nbsp;属性： ​ 1).CGSize itemSize &nbsp;–&nbsp;定义每一个item的size，可以快捷地给cell设置大小&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2).CGFloat minimumLineSpacing &nbsp;–&nbsp;最小行间距&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3).CGFloat minimumInteritemSpacing &nbsp;–&nbsp;最小cell之间的距离&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4).UIEdgeInsets sectionInset &nbsp;–&nbsp;设置UIcollectionView整体的组内边距&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5).CGSize headerReferenceSize &nbsp;–&nbsp;设置supplementary header View的大小&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;6).CGSize footerReferenceSize &nbsp;–&nbsp;设置supplementary footer View的大小&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;7).UICollectionViewScrollDirection scrollDirection &nbsp;–&nbsp;设置UICollectionView的滚动方向 2.UICollectionViewAttributes布局属性 &nbsp;&nbsp;&nbsp;&nbsp;属性： ​ 1).CGRect frame &nbsp;–&nbsp;布局视图的frame&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2).CGPoint center &nbsp;–&nbsp;视图中心点&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3).CGSize size &nbsp;–&nbsp;视图尺寸&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;4).CGAffineTransform transform &nbsp;–&nbsp;转场属性&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5).CGFloat alpha &nbsp;–&nbsp;透明度&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;6).NSInteger zIndex &nbsp;–&nbsp;层级(数字越大，层级越高)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;7).registerClass:forDecorationViewOfKind &nbsp;–&nbsp;注册Decoration View 3.UICollectionViewLayout自定义布局 ​ 一些处理布局的方法 ​ 1).@interface UICollectionViewLayout (UISubclassingHooks) 布局UICollectiojnView的子视图 ​ 2).@interface UICollectionViewLayout (UIUpdateSupportHooks) 布局删除插入动作 ​ 3).@interface UICollectionViewLayout (UIReorderingSupportHooks) 移动动作布局","link":"/2024/07/04/iOS/iOS_UICollectionView%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"title":"UI控件","text":"UI控件 UI控件UIView 视图类用法： UIView *view = [[UIView alloc] init]; 常见属性 1. 获得自己的父控件对象 @property (nonatomic, readonly) UIView *superview; //父控件只有一个 2. 获得自己的子控件对象 @property (nonatomic, readonly) NSArray *subviews; //子控件可能有很多个 3. 获得控件的Tag @property(nonatomic) NSInteger tag; 4. 控件的形变属性 -- 旋转角度，比例缩放，平移等 @property(nonatomic) CGAffineTransform transform; 5. 控件矩形框在父控件上的位置和尺寸 @property(nonatomic) CGRect frame; 用法： targetView.frame = CGRectMake(x, y, width, height); 6. 控件矩形的位置和尺寸（以自己为坐标原点） @property(nonatomic) CGRect bounds; 7. 控件中点的位置（控件中心点） @property(nonatomic) CGpoint center; 常用方法： 1. 添加一个子控件 - (void) addSubview: (UIView *) view; 用法： [self.view addSubview(targetView)]; 2. 将自己从父控件中移除 - (void) removeFromSuperview; 用法： [targetView removeFromSuperView]; UILabel 标签类 – 父类：UIView用法： UILabel *label = [[UILabel alloc] init]; 常见属性：(可使用父类的属性) 1. 显示的文字 @property(nonatomic, copy) NSString *text; 2. 显示的字体,可设置字体的大小 @property(nonatomic, retain) UIFont *font; 3. 文字的颜色 @property(nonatomic) UIColor *textColor; 4. 背景颜色 @property(nonatomic) UIColor *backgroundColor; 5. 对齐的样式 @property(nonatomic) NSTextAlignment; textAlignment; 6. 文字行数 @property(nonatomic) NSInteger numberOfLines; 7. 换行模式 @property(nonatomic) NSLineBreakMode lineBreakMode; 8. 设置阴影 @property(nontaomic) UIColor *shadowColor; 9. 阴影显示位置 @property(nonatomic) CGSize shadowOffset; UIImageVIew 图像视图 – 父类：UIView用法： UIImageView *imageView = [[UIImageView alloc] init]; 常见属性：(可用父类属性) 1. 设置要显示的图片 @property (nullable, nonatomic, strong) UIImage *image; 使用： imageView.image = [UIImage imageNamed: @&quot;1&quot;]; 2. 设置图片的样式（枚举） @property(nonatomic) UIViewContentMode contentMode; UIButton 按钮控件 – 父类：UIControl &lt;- UIView用法： 按钮状态： 1. 普通状态 normal 对应情况：Default 枚举常量： UIControlStateNormal 2. 高亮状态 highlighted 枚举常量： UIControlStateHighlihted 3. 失效状态 disabled 枚举常量： UIControlStatedisabled 常用属性：(可使用父类属性) 注意有些属性需要对应按钮的不同状态分别设置 1. 设置按钮类型（枚举类型） @property(nonatomic,readonly) UIButtonType buttonType; 使用： 结合按钮初始化方法一起使用： UIButton *button = [UIButton buttonWithType: 枚举类型的状态变量]; 2. 常用方法： 以set开头的设置方法，可去类文件中查找并使用 1. 设置文字标题 setTitle: forState: 2. 设置内容图片 setImage: forState: 3. 设置背景图片 setBackgroundImage: forState: 4. 设置点击按钮执行的方法 - (IBACtion) clickbutton (UIButton *) sender; 5. 监听按钮点击 addTarget: (让谁做事情 -- self) action: @selector(做什么事情 -- 方法) forControlEvent: (事件 -- 对按钮触发了怎样的事件) UITableView","link":"/2024/07/04/iOS/iOS_UI%E6%8E%A7%E4%BB%B6/"},{"title":"数据竞争","text":"多线程数据竞争demo~~~ 数据竞争代码举例以及用互斥锁解决123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051// ViewController.m//售票员卖票demo@interface ViewController() @property(nonatomic, strong) NSThread *threadA;@property(nonatomic, strong) NSThread *threadB;@property(nonatomic, strong) NSThread *threadC; @end @implementation ViewController- (void)touchesBegan:(NSSet&lt;UITouch *&gt; *)touches withEvent:(UIEvent *)event { self.ticketCount = 100; //开启三个售票员线程 self.threadA = [[NSThread alloc] initWithTarget:self selector:@selector(saleTicket) object:nil]; self.threadB = [[NSThread alloc] initWithTarget:self selector:@selector(saleTicket) object:nil]; self.threadC = [[NSThread alloc] initWithTarget:self selector:@selector(saleTicket) object:nil]; //线程属性设置 self.threadA.name = @&quot;售票员A&quot;; self.threadB.name = @&quot;售票员B&quot;; self.threadC.name = @&quot;售票员C&quot;; //启动线程 [self.threadA start]; [self.threadB start]; [self.threadC start]; }- (void)saleTicket { while(1) { @synchronized (self) { //对于每一次卖票的模块上锁，保证同一时间只有一位售票员在卖票 if(self.ticketCount &gt; 0) { //卖出去一张票 for(int i = 1; i &lt;= 100000; i++); //增加程序执行时间，方便观察结果 NSLog(@&quot;%@卖出去一张，还剩下%zd张&quot;, [NSThread currentThread].name, self.ticketCount - 1); self.ticketCount--; } else { NSLog(@&quot;票已售罄&quot;); break; } } }}@end","link":"/2024/07/03/iOS/iOS_datarace/"},{"title":"gcd","text":"多线程之gcd记录~~~ GCD (grand central dispatch)概念gcd是一个强大的中枢调度器, 基于C语言实现, 解决多核的并行运算，能够自动利用更多的CPU内核，自动管理线程的生命周期. 任务: 执行什么操作(可以理解为函数的内容) 队列: 用来存放、安排任务. 不同的队列类型有不同的执行任务的策略.(串行队列在当前线程按顺序执行任务, 并发队列创建多个线程并行地执行任务) gcd的使用逻辑定制任务, 将任务添加到队列 – 先进先出地自动取出任务放到对应线程中执行 同步和异步同步和异步是指任务的类型 同步执行: 只能在当前线程执行任务，不能开启新线程 123456//使用block块封装任务dispatch_sync(dispatch_queue_t _Nonnull queue, ^{ });//使用函数封装任务dispatch_sync_f(dispatch_queue_t queue, void * context, dispatch_function_t work);//队列 - 函数形参(没有为null) - 调用函数名 异步执行: 可以开启新线程, 并在新线程中执行任务 123456//使用block块封装任务dispatch_async(dispatch_queue_t _Nonnull queue, ^{ });//使用函数封装任务dispatch_async_f(dispatch_queue_t queue, void * context, dispatch_function_t work); //队列 - 函数形参(没有为null) - 调用函数名 串行和并发串行和并发是指队列中任务的执行策略 并发队列 (Dispatch Concurrent Queue): 可以让多个任务并发执行 (自动开启多个线程同时执行任务) – 并发功能只在异步函数下生效 1234567//并发队列/*参数1：C语言字符串 -- 队列标签参数2：队列类型 DISPATCH_QUEUE_CONCURRENT -- 并发*/dispatch_queue_t queue = dispatch_queue_create(&quot;label1&quot;, DISPATCH_QUEUE_CONCURRENT); 全局并发队列: 默认存在，且对应有高，默认，低，后台优先级的四种并发队列，使用时只选择其中一个；而create函数是从0开始创建一个并发队列 123456//全局并发队列/*参数1：队列优先级参数2：默认为0*/dispatch_queue_t queue = dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_BACKGROUND, 0); 串行队列 (Dispatch Serial Queue): 让任务一个接一个地执行 12//串行队列dispatch_queue_t queue = dispatch_queue_create(&quot;label2&quot;, DISPATCH_QUEUE_SERIAL); 主队列: 会通过主线程执行UI刷新, 用户输入处理等任务 12//主队列（主线程执行任务）dispatch_queue_t queue = dispatch_get_main_queue(); 串行, 并行队列以及同步,异步函数的实践 异步函数 + 并发队列: 会开启多条新线程，队列中的任务异步执行 123456789101112131415161718192021- (void)asyncConcurrent { //1.创建队列 -- 并发队列 dispatch_queue_t queue = dispatch_queue_create(&quot;conQueue&quot;, DISPATCH_QUEUE_CONCURRENT); //2.封装异步任务并添加到队列中 /* 参数1：队列名 参数2：要执行的任务 */ //测试是否开启了多条线程 dispatch_async(queue, ^{ NSLog(@&quot;download1 --- %@&quot;, [NSThread currentThread]); }); dispatch_async(queue, ^{ NSLog(@&quot;download1 --- %@&quot;, [NSThread currentThread]); }); dispatch_async(queue, ^{ NSLog(@&quot;download1 --- %@&quot;, [NSThread currentThread]); });} 异步函数 + 串行队列 – 会开启一条新线程，队列中的任务串行执行 123456789101112131415- (void)asyncSerial { //创建队列 -- 串行队列 dispatch_queue_t queue = dispatch_queue_create(&quot;serQueue&quot;, DISPATCH_QUEUE_SERIAL); //异步函数 dispatch_async(queue, ^{ NSLog(@&quot;download1 --- %@&quot;, [NSThread currentThread]); }); dispatch_async(queue, ^{ NSLog(@&quot;download1 --- %@&quot;, [NSThread currentThread]); }); dispatch_async(queue, ^{ NSLog(@&quot;download1 --- %@&quot;, [NSThread currentThread]); });} 异步函数 + 主队列: 不会开启线程，队列中任务都在主线程中执行 123456789101112131415- (void)asyncMain { //创建主队列 dispatch_queue_t queue = dispatch_get_main_queue(); //异步函数 dispatch_async(queue, ^{ NSLog(@&quot;download1 --- %@&quot;, [NSThread currentThread]); }); dispatch_async(queue, ^{ NSLog(@&quot;download1 --- %@&quot;, [NSThread currentThread]); }); dispatch_async(queuaaa NSLog(@&quot;download1 --- %@&quot;, [NSThread currentThread]); });} 同步函数 + 并发队列: 不会开启新线程 123456789101112131415- (void)syncConcurrent { //创建并发队列 dispatch_queue_t queue = dispatch_queue_create(&quot;conQueue&quot;, DISPATCH_QUEUE_CONCURRENT); //同步函数 dispatch_sync(queue, ^{ NSLog(@&quot;download1 --- %@&quot;, [NSThread currentThread]); }); dispatch_sync(queue, ^{ NSLog(@&quot;download1 --- %@&quot;, [NSThread currentThread]); }); dispatch_sync(queue, ^{ NSLog(@&quot;download1 --- %@&quot;, [NSThread currentThread]); });} 同步函数 + 串行队列: 不会开启线程 123456789101112131415- (void)syncSerial { //创建串行队列 dispatch_queue_t queue = dispatch_queue_create(&quot;serQueue&quot;, DISPATCH_QUEUE_SERIAL); //同步函数 dispatch_sync(queue, ^{ NSLog(@&quot;download1 --- %@&quot;, [NSThread currentThread]); }); dispatch_sync(queue, ^{ NSLog(@&quot;download1 --- %@&quot;, [NSThread currentThread]); }); dispatch_sync(queue, ^{ NSLog(@&quot;download1 --- %@&quot;, [NSThread currentThread]); });} 同步函数 + 主队列: 产生死锁 避免死锁: 用子线程调用syncMain()123456789101112131415- (void)syncMain { //创建主队列 dispatch_queue_t queue = dispatch_get_main_queue(); //同步函数 dispatch_sync(queue, ^{ NSLog(@&quot;download1 --- %@&quot;, [NSThread currentThread]); }); dispatch_sync(queue, ^{ NSLog(@&quot;download1 --- %@&quot;, [NSThread currentThread]); }); dispatch_sync(queue, ^{ NSLog(@&quot;download1 --- %@&quot;, [NSThread currentThread]); });} 回到: [[多线程2__多线程开发#实现汇总]] gcd实现线程间通信1234567891011121314151617181920212223242526272829303132333435363738//网络图片下载Demo -- GCD实现#import &quot;ViewController.h&quot;@interface ViewController ()@property(nonatomic, strong) UIImageView *imageView;@end@implementation ViewController- (void)touchesBegan:(NSSet&lt;UITouch *&gt; *)touches withEvent:(UIEvent *)event { //1.使用GCD开子线程 -- 使用异步函数 dispatch_async(dispatch_get_global_queue(0, 0), ^{ //获取全局并发队列 //封装任务 //确定图片URL NSURL *url = [NSURL URLWithString:@&quot;https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fa1.att.hudong.com%2F62%2F02%2F01300542526392139955025309984.jpg&amp;refer=http%3A%2F%2Fa1.att.hudong.com&amp;app=2002&amp;size=f9999,10000&amp;q=a80&amp;n=0&amp;g=0n&amp;fmt=jpeg?sec=1613890070&amp;t=9b041b83f4ddfe8c165547120f5aa589&quot;]; //根据URL下载图片二进制数据到本地 NSData *imageData = [NSData dataWithContentsOfURL:url]; //图片格式转换 UIImage *image = [UIImage imageWithData:imageData]; //更新UI dispatch_async(dispatch_get_main_queue(), ^{ self.imageView.image = image; NSLog(@&quot;UI--- %@&quot;, [NSThread currentThread]); }); //同步函数更新UI dispatch_sync(dispatch_get_main_queue(), ^{ //此时任务在子线程中执行，因此使用主队列不会造成死锁 self.imageView.image = image; NSLog(@&quot;UI--- %@&quot;, [NSThread currentThread]); }); });}@end 回到: [[多线程2__多线程开发#线程间通信]] gcd注意事项通过dispatch_async(queue, ^{block})将block追加到dispatch queue(无论Concurrent或Serial Queue)中后, 立即通过dispatch_release(queue)释放, 是否会影响block的执行?不会. 首先: dispatch_async或dispatch_sync表示追加异步或同步任务到串行队列或并发队列中执行. queue并不是OC中类似”block”的对象, 因此没有ARC来自动管理它的内存, 因此需要手动对它(队列对象)进行释放 其次: 通过 dispatch_async将block追加到queue中, 本质上该block通过dispatch retain持有了queue. 因此就算在追加后立即对queue进行release操作, 该queue由于被block持有也不会废弃, 因此block能够正常执行.","link":"/2024/07/03/iOS/iOS_gcd/"},{"title":"死锁","text":"多线程死锁理解笔记(乱)~~~ 使用disptach_sync在串行队列(包括主队列)导致的死锁问题原理解释:","link":"/2024/07/03/iOS/iOS_deadlock/"},{"title":"pthread","text":"多线程pthread记录~~~ 1234567891011121314151617181920212223242526// ViewController.m#import &lt;pthread.h&gt;- (void)viewDidLoad { [super viewDidLoad]; //1.创建线程对象 pthread_t thread; //2.线程创建函数 //1).线程对象 -- 地址传递 //2).线程的属性 //3).指向函数的指针 //4).前面函数要接收的参数 -- NULL pthread_create(&amp;thread, NULL, func, NULL); //3.判断两条线程是否相等 pthread_equal();}void *func(*void) { NSLog(@&quot;%@-----&quot;, [NSThread currentThread]); return NULL;}","link":"/2024/07/03/iOS/iOS_pthread/"},{"title":"单例模式","text":"单例模式记录~~~ 单例模式提供了一种创建对象的最佳方式。这种模式涉及到一个单一的类，该类负责创建自己的对象，同时确保只有单个对象被创建。 单例模式的作用 保证在程序运行过程中，一个类只有一个实例，该实例易于供外界访问，从而方便地控制了实例个数，节约系统资源 单例模式的使用场合 在整个应用程序中，需要共享一份资源（资源只需要初始化一次） 单例模式的实现 ARC环境下实现单例模式1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253方法：懒加载，类方法，协议实现//ToolBox.m#import &quot;ToolBox.h&quot;@interface ToolBox() &lt;NSCopying, NSMutableCopying&gt;@end@implementation ToolBox//0.提供全局变量static ToolBox *toolBox;//懒加载 --- 保证只分配一次存储空间//alloc -&gt; allocWithZone+ (instancetype)allocWithZone:(struct _NSZone *)zone { //线程安全问题 //1.互斥锁// @synchronized (self) {// if(toolBox == nil) {// toolBox = [super allocWithZone:zone];// }// } //2.GCD一次性代码 -- 程序运行期间只执行一次 static dispatch_once_t onceToken; dispatch_once(&amp;onceToken, ^{ toolBox = [super allocWithZone:zone]; }); return toolBox;} //类方法//1.方便访问 -- 外界只需调用类方法获得该类实例//2.表明身份 -- 从类方法识别该类是单例//3.命名规范 -- share+类名|default+类名|share|default|类名+(instancetype)shareTool { return [[self alloc] init];}//协议实现//copy -&gt; copyWithZone- (id)copyWithZone:(NSZone *)zone { return toolBox;}//mutableCopy -&gt; mutableCopyWithZone- (id)mutableCopyWithZone:(NSZone *)zone { return toolBox;}@end 12345678910111213141516171819202122232425262728//ViewController.m#import &quot;ViewController.h&quot;#import &quot;ToolBox.h&quot;@implementation ViewController//ARC环境下实现单例模式- (void)viewDidLoad { [super viewDidLoad]; //1.懒加载实现 ToolBox *tool1 = [[ToolBox alloc] init]; ToolBox *tool2 = [[ToolBox alloc] init]; ToolBox *tool3 = [ToolBox new]; //2.类方法实现 ToolBox *tool4 = [ToolBox shareTool]; //3.实现协议中的copy方法，将已有的toolBox对象返回即可 ToolBox *tool5 = [tool1 copy]; ToolBox *tool6 = [tool1 mutableCopy]; NSLog(@&quot;t1:%p t2:%p t3:%p t4:%p t5:%p t6:%p&quot;, tool1, tool2, tool3, tool4, tool5, tool6);}@end","link":"/2024/07/04/iOS/iOS_%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/"},{"title":"观察者模式","text":"观察者模式记录~~~ 什么是观察者模式 观察者模式定义：观察者模式定义了一种一对多的依赖关系，让多个观察者对象同时监听某一个主题对象。这个主题对象在状态上发生变化时，会通知所有观察者对象，使它们能够自动更新自己。 iOS中实现观察者模式：Notification、KVO。 Notification – 通知 现有对象A和B，A对B的变化感兴趣，就注册为B的观察者，当B发生变化时通知A，告知B发生了变化。 对于感兴趣的A来说，在A这里定义通知，也就是注册观察者（A就是观察者，定义怎么观察的以及观察到了会做些什么） 123456789//注册观察者[[NSNotificationCenter defaultCenter] addObserver:self selector:@selector(notice:) name:@&quot;tongzhi&quot; object:nil]; //观察到变化后做什么事情- (void)notice:(id)sender { NSLog(@&quot;%@&quot;, sender);} 对于变化源B来说，在B这里发出通知 12345678//创建通知对象//Name是通知的名称 object是通知的发布者，也就是发布通知的对象 userInfo是一些额外的信息， 字典类NSNotification *notification = [NSNotification notificationWithName:@&quot;tongzhi&quot; object:nil userInfo:nil]; //发送通知[[NSNotificationCenter defaultCenter] postNotification:notification]; 在dealloc中移除观察者1234- (void)dealloc { //根据name和object删除对应的观察者，如果object设置为nil，则删除所有name匹配的观察者 [[NSNotificationCenter defaultCenter] removeObserver:self name:@&quot;tongzhi&quot; object:nil];} KVO – Key Value Observing KVO，即键值观察，它是观察着模式的一种衍生。其基本思想是，对目标对象的某属性添加观察，当该属性发生变化时，会自动通知观察者。相比于NotificationCenter的post通知来说简单了许多。 首先，给目标对象的属性添加观察 1234- (void)addObserver:self forKeyPath:@&quot;name&quot; options:NSKeyValueObservingOptionNew|NSKeyValueObservingOptionOld //能够记录旧值和新值 context:nil 其次，实现下面方法来接收通知（当被观察的属性发生变化时，观察者立马会得到通知） 12345678910- (void)observeValueForKeyPath:(nullable NSString *)keyPath //目标属性，需判断是否和自己所观察的属性一致 ofObject:(nullable id)object //目标对象，需判断是否和自己所观察的对象一致 change:(nullable NSDictionary&lt;NSString*, id&gt; *)change context:nil//如果收到的通知经过判断不是自己要观察的，则将该情况交给父类处理，因为父类也有可能使用了KVO//[super observeValueForKeyPath:keyPath ofObject:object change:change context:context]; 最后，移除观察者 1- (void)removeObserver:self forKeyPath:@“name”; KVO的原理 当某个类的对象第一次被观察时，系统就会在运行期动态地创建该类的一个派生类，在这个派生类中重写基类中被观察属性的 setter 方法，在setter方法里使其具有通知机制。同时派生类还重写了 class 方法以“欺骗”外部调用者它就是起初的那个类。然后系统将这个对象的 isa 指针指向这个新诞生的派生类，因此这个对象就成为该派生类的对象了，因而在该对象上对 setter 的调用就会调用重写的 setter，从而激活键值通知机制。此外，派生类还重写了 dealloc 方法来释放资源。 在重写的setter里，给属性赋值的前后分别调用了两个方法： 12- (void)willChangeValueForKey:(NSString *)key; //赋值前- (void)didChangeValueForKey:(NSString *)key; //赋值后 在didChangeValueForKey:(NSString *)key方法中会调用： 1234- (void)observeValueForKeyPath:(nullable NSString *)keyPath ofObject:(nullable id)object change:(nullable NSDictionary&lt;NSString*, id&gt; *)change context:nil KVO使用注意 只有使用属性的setter方法，或通过key-path来设置属性值，观察者对象才会获得通知 12345678常见的几种设置方式：1.遵循使用属性的setter方法self.name = @&quot;changed&quot;;[self setName:@&quot;changed&quot;];2.通过key-path设置[self setValue:[NSString stringWithFormat:@&quot;changed&quot;] forKey:@&quot;name&quot;]; 观察者在使用结束后一定要在dealloc中移除，否则会导致资源泄漏 通知方法（observeValueForKeyPath）中，change字典保存了属性变更的信息 12NSLog(@&quot;the old value is %@&quot;, [change objectForKey:@&quot;old&quot;]); //旧值NSLog(@&quot;the new value is %@&quot;, [change objectForKey:@&quot;new&quot;]); //新值","link":"/2024/07/04/iOS/iOS_%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F/"},{"title":"iOS网络之多线程","text":"记录iOS多线程开发的基本知识和使用方法, 积累iOS开发经验~~~ 一些基本概念 一个应用程序可以对应多个进程, 每个进程中至少有一个线程, 进程中的线程共享该进程的资源. 线程执行任务的方式 – 串行（任务和任务之间有执行顺序，即多个任务一个一个地按顺序执行，一个线程同时只能执行一个任务） 单个进程中的每条线程可以并行执行任务 同一时间CPU只能处理一条线程，即只有一条线程在工作. 所以多线程并发执行，实则是CPU快速地在线程之间调度切换. 原子性与非原子性atomic 原子属性 为setter方法加锁（默认为atomic） 线程安全，消耗大量资源 nonatomic 非原子属性 不会为setter方法加锁 非线程安全，适合小内存移动设备 多线程的优缺点 优点 适当提高程序的执行效率和资源利用率 缺点 空间开销：内核数据结构，栈空间 时间开销：约90ms的创建时间 性能降低：在开启大量线程时降低程序性能，同时CPU调度线程时开销更大 程序设计：线程之间通信，多线程数据共享（同一数据被多个线程共享导致数据安全问题）更加复杂 主线程与子线程 主线程的概念一个iOS程序运行后，默认开启一条“主线程”或“UI线程” 主线程的作用 显示/刷新UI 处理UI事件（点击，滚动，拖拽等） 主线程注意事项 凡是和UI相关的操作必须在主线程中执行 不要将耗时操作放在主线程中 – 会卡住主线程，严重影响UI流畅度，降低用户体验 子线程的概念用来执行耗时操作的线程 多线程实现方案 技术方案 简介 语言 线程生命周期 使用频率 pthread 1.通用的多线程API2.适用于Unix/Linux/Windows等系统3.跨平台/可移植4.使用难度较大 C语言 程序员管理 少 NSThread 1.更加面向对象2.简单易用，可直接操作线程对象 OC 程序员管理 正常 gcd 1.旨在代替NSThread等线程技术2.充分利用设备的多核资源 C 自动管理 经常使用 NSOperation 1.基于GCD，增加了一些简单功能2.更加面向对象 OC 自动管理 经常使用 多线程安全问题 数据竞争当多个线程同时访问和修改同一共享资源且至少一个是写操作时，会导致数据竞争。 死锁当两个或多个线程互相等待对方释放资源时，会导致死锁，所有相关线程都会被永远阻塞。 线程饥饿(Thread Starvation)当某些线程长时间得不到资源访问权时，会导致线程饥饿问题。 上下文切换开销(Context Switching Overhead)上下文切换开销是指CPU在不同线程之间切换时保存和恢复线程状态的过程. 频繁的上下文切换会导致性能开销增加，影响应用的响应速度和效率。 12345678910111213141516dispatch_queue_t queue = dispatch_queue_create(&quot;com.example.concurrentQueue&quot;, DISPATCH_QUEUE_CONCURRENT);// 问题举例 for (int i = 0; i &lt; 1000; i++) { dispatch_async(queue, ^{ NSLog(@&quot;Task %d&quot;, i); });}// 解决方法// 减少任务的数量或调整任务的粒度，减少不必要的上下文切换。dispatch_async(queue, ^{ for (int i = 0; i &lt; 1000; i++) { NSLog(@&quot;Task %d&quot;, i); }}); 保证线程安全的方式 使用同步机制 互斥锁 (Mutex) : 使用 @synchronized、NSLock、pthread_mutex 等来保护临界区，确保同一时刻只有一个线程可以访问共享资源。 递归锁 (NSRecursiveLock): 用于允许同一线程多次获得同一个锁，而不会导致死锁。 条件锁 (NSConditionLock): 用于处理线程之间的依赖关系，允许线程在某个条件满足时继续执行。 使用gcd 串行队列 并发队列 异步任务 使用原子操作 OSAtomic: 提供一些原子操作函数，如 OSAtomicIncrement32，但在 iOS 10 之后被 stdatomic 替代。 stdatomic: C11 标准库中的原子操作，提供对基本类型的原子读写操作。 使用线程安全的容器 NSOperationQueue: 提供了更高级的线程管理和任务调度机制，适用于需要更复杂依赖关系和优先级管理的场景。 线程安全的集合类: 如 NSCache 等，内部已经实现了线程安全机制。 避免共享状态 尽量减少共享状态，通过消息传递或复制数据来避免多个线程同时访问同一个资源。 使用不可变对象 尽可能使用不可变对象（如 NSString、NSArray 等），避免在多个线程中修改同一个对象的状态。 线程间通信 概念A线程传递数据给B线程A线程执行完特定任务后，转到B线程继续执行任务 NSThread线程间通信gcd线程间通信一些demo I 延迟执行1234567891011121314151617181920212223242526272829303132//ViewController.m- (void)touchesBegan:(NSSet&lt;UITouch *&gt; *)touches withEvent:(UIEvent *)event { [self delay];}//延迟执行- (void)delay { NSLog(@&quot;start---- delay running&quot;); //1.延迟执行的第一种方法 [self performSelector:@selector(task) withObject:nil afterDelay:2.0]; //2.0秒延迟之后执行 //2.延迟执行的第二种方法 [NSTimer scheduledTimerWithTimeInterval:2.0 target:self selector:@selector(task) userInfo:nil repeats:YES]; //在2.0秒延迟之后每2.0秒执行一次task方法 //3.GCD实现延迟执行 /* 参数1：DISPATCH_TIME_NOW 从现在开始计算时间 参数2：延迟的时间 2.0 GCD时间单位：纳秒 参数3：队列 */ dispatch_queue_t queue = dispatch_get_main_queue(); //使用主队列 //dispatch_queue_t queue = dispatch_get_global_queue(0, 0); //使用全局并发队列 dispatch_after(dispatch_time(DISPATCH_TIME_NOW, (int64_t)(2.0 * NSEC_PER_SEC)), queue, ^{ //从现在开始计时，2.0*10e9纳秒延迟后执行block NSLog(@&quot;GCD --- %@&quot;, [NSThread currentThread]); });} - (void)task { NSLog(@&quot;task --- %@&quot;, [NSThread currentThread]);} 一次性代码 (不可放入懒加载中)1234567//一次性代码 -- 整个应用程序运行期间只执行一次- (void)once { static dispatch_once_t onceToken; dispatch_once(&amp;onceToken, ^{ NSLog(@&quot;---once---&quot;); });} 栅栏函数 – 控制并发队列任务执行顺序(栅栏后的任务等待栅栏执行后才会执行)123456789101112131415161718192021222324252627282930//ViewController.m- (void)touchesBegan:(NSSet&lt;UITouch *&gt; *)touches withEvent:(UIEvent *)event { //0.创建并发队列 dispatch_queue_t que = dispatch_queue_create(&quot;download&quot;, DISPATCH_QUEUE_CONCURRENT); //1.异步函数开线程 dispatch_async(que, ^{ //任务1 NSLog(@&quot;download1---%@&quot;, [NSThread currentThread]); }); dispatch_async(que, ^{ //任务2 NSLog(@&quot;download2---%@&quot;, [NSThread currentThread]); }); //栅栏函数 -- 不可使用全局并发队列 dispatch_barrier_async(que, ^{ NSLog(@&quot;++++++++++++++++&quot;); }); dispatch_async(que, ^{ //任务3 NSLog(@&quot;download3---%@&quot;, [NSThread currentThread]); }); dispatch_async(que, ^{ //任务3 NSLog(@&quot;download4---%@&quot;, [NSThread currentThread]); });} 快速迭代123456789101112131415161718192021222324252627282930313233343536373839404142//文件剪切Demo -- 快速迭代并发遍历并剪切文件//开子线程和主线程一起完成并发任务，任务并发执行- (void)apply { /* 参数1：遍历次数 参数2：并发队列 参数3：遍历索引 */ dispatch_apply(100, dispatch_get_global_queue(0, 0), ^(size_t index) { NSLog(@&quot;%zd --- %@&quot;, index, [NSThread currentThread]); });}- (void)moveFile { //1.拿到文件路径 NSString *from = @&quot;/Users/qiaoyibo/Downloads/from&quot;; //2.获得目标文件路径 NSString *to = @&quot;/Users/qiaoyibo/Downloads/to&quot;; //3.得到目录下面的所有文件(名) NSArray *subPaths = [[NSFileManager defaultManager] subpathsAtPath:from]; //4.遍历所有文件，执行剪切操作 NSInteger count = subPaths.count; dispatch_apply(count, dispatch_get_global_queue(0, 0), ^(size_t i) { //4.1 拼接文件全路径 //拼接时自动添加路径间的'/' NSString *fullPath = [from stringByAppendingPathComponent:subPaths[i]]; NSString *tofullPath = [to stringByAppendingPathComponent:subPaths[i]]; //4.2 执行剪切操作 /* 参数1：要剪切的文件在哪 参数2：文件应该被存放到哪里 参数3：默认为nil */ [[NSFileManager defaultManager] moveItemAtPath:fullPath toPath:tofullPath error:nil]; });} 队列组1234567891011121314151617181920212223242526272829//队列组的拦截监听作用- (void)touchesBegan:(NSSet&lt;UITouch *&gt; *)touches withEvent:(UIEvent *)event { //1.创建队列 dispatch_queue_t queue = dispatch_get_global_queue(0,0); //2.创建队列组 dispatch_group_t group = dispatch_group_create(); //异步函数 /* 1)封装任务 2)把任务添加到队列中 3)会监听任务的执行情况，通知group */ dispatch_group_async(group, queue, ^{ NSLog(@&quot;1-----%@&quot;, [NSThread currentThread]); }); dispatch_group_async(group, queue, ^{ NSLog(@&quot;2-----%@&quot;, [NSThread currentThread]); }); dispatch_group_async(group, queue, ^{ NSLog(@&quot;3-----%@&quot;, [NSThread currentThread]); }); //拦截通知，当队列组中所有的任务都执行完毕的时候会进入到下面的方法 dispatch_group_notify(group, queue, ^{ NSLog(@&quot;-----拦截任务组-----&quot;); });} 12345678910111213141516171819202122232425262728293031323334353637383940//将后续任务加入队列组- (void)test { //1.创建队列 dispatch_queue_t queue = dispatch_get_global_queue(0, 0); //2.创建队列组 dispatch_group_t group = dispatch_group_create(); //3.在该方法后面的”异步任务“会被纳入到队列组监听范围，进入群组 //enter和leave 必须配对使用 dispatch_group_enter(group); dispatch_async(queue, ^{ NSLog(@&quot;1----%@&quot;, [NSThread currentThread]); //离开群组 dispatch_group_leave(group); }); dispatch_group_enter(group); dispatch_async(queue, ^{ NSLog(@&quot;2----%@&quot;, [NSThread currentThread]); dispatch_group_leave(group); }); //拦截通知 //该方法是异步的 dispatch_group_notify(group, queue, ^{ NSLog(@&quot;------dispatch_group_notify-------&quot;); }); NSLog(@&quot;------dispatch_group_notify------&quot;);//异步测试 //等待（死等） //该方法是阻塞的 dispatch_group_wait(group, DISPATCH_TIME_FOREVER); NSLog(@&quot;------dispatch_group_wait------&quot;); //阻塞测试} 123456789101112131415161718192021222324252627282930313233343536373839404142434445//下载图片1和2，合成并显示图片- (void)test { //获得全局并发队列 dispatch_queue_t queue = dispatch_get_global_queue(0, 0); //获取队列组 dispatch_group_t group = dispatch_group_create(); //开子线程下载图片1 dispatch_group_async(queue, group, ^{ NSURL *url = [NSURL URLWithString:@&quot;&quot;]; NSData *imageData = [NSData dataWithContentsOfURL:url]; UIImage *image1 = [UIImage imageWithData:imageData]; }); //开子线程下载图片2 dispatch_group_async(queue, group, ^{ NSURL *url = [NSURL URLWithString:@&quot;&quot;]; NSData *imageData = [NSData dataWithContentsOfURL:url]; UIImage *image1 = [UIImage imageWithData:imageData]; }); //合成图片 dispatch_group_notify(group, queue, ^{ //创建图形上下文 UIGraphicsBeginImageContext(CGSizeMake(200, 200)); //画图1 [self.image1 drawInRect:CGRectMake(0, 0, 200, 200)]; //画图2 [self.image2 drawInRect:CGRectMake(0, 100, 200, 100)]; //根据上下文得到一张图片 UIImage *image = UIGraphicsGetImageFromCurrentImageContext(); //关闭上下文 UIGraphicsEndImageContext(); //更新UI dispatch_async(dispatch_get_main_queue(), ^{ NSLog(@&quot;UI---------%@&quot;, [NSThread currentThread]); self.imageView.image = image; }); });}","link":"/2024/07/04/iOS/iOS%E7%BD%91%E7%BB%9C%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"title":"markdown 常用语法总结","text":"总结了常用的markdown语法, 方便平常整理笔记时使用~~ 标题 使用 # 号表示标题，支持 1 到 6 级标题。 123456# 一级标题## 二级标题### 三级标题#### 四级标题##### 五级标题###### 六级标题 段落 段落之间需要空一行。 123这是一个段落。这是另一个段落。 强调 使用 * 或 _ 表示斜体，使用 ** 或 __ 表示粗体。 1234*斜体*_斜体_**粗体**__粗体__ 删除线 使用 ~~ 表示删除线。 1~~删除线~~ 引用 使用 &gt; 表示引用。 1&gt; 这是一个引用。 列表 无序列表使用 -、* 或 + 表示无序列表。 12345678910- 项目一- 项目二 - 子项目 - 子项目* 项目一* 项目二+ 项目一+ 项目二 有序列表使用数字加点表示有序列表。 12341. 项目一2. 项目二 1. 子项目 2. 子项目 链接 使用 显示文本 表示链接。 1[Google](https://www.google.com) 图片 使用 ![替代文本](图片地址) 插入图片。 1![描述](https://www.example.com/image.jpg) 代码 行内代码使用反引号 ` 表示行内代码。 1这是 `inline code`。 代码块使用三个反引号 ``` 或四个空格表示代码块。 123// ```javascript// console.log('Hello, world!');// ``` 公式 行内公式1$f_{w,b}(x) = wx + b$ 块级公式123$$f_{w,b}(x) = wx + b$$ 表格 使用 | 和 - 创建表格。 1234| 标题一 | 标题二 || ------ | ------ || 单元格 | 单元格 || 单元格 | 单元格 | 水平线 使用三个及以上的 -、* 或 _ 表示水平线。 123---***___ 注脚 使用 [^注脚] 表示注脚。 123这是一个带注脚的文本[^1]。[^1]: 这是注脚内容。 任务列表 使用 - [ ] 表示未完成任务，- [x] 表示已完成任务。 12- [x] 已完成任务- [ ] 未完成任务 转义 使用反斜杠 \\ 转义特殊字符。 1\\*这个文本没有被强调\\*","link":"/2024/07/04/markdown/markdown%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95%E6%80%BB%E7%BB%93/"},{"title":"iOS面试题记录","text":"iOS客户端开发工程师面试题记录~~ Objective-C 语言特性：1.面向对象中的封装, 继承, 多态分别是什么? 体现在哪些地方? 是怎么使用的?2.动态类型（id类型）是什么? 在OC中是怎么使用的? 为什么需要使用id类型? 它和其他的类型有什么区别吗?3.动态绑定（关键词@selector）是什么? 在OC中是如何使用的? 为什么需要使用动态绑定? 它的原理是什么?4.动态加载：OC中有没有动态加载? 是如何使用的?5.内存管理: OC中对于栈和堆是如何使用的? 他们之间有什么区别? 什么时候会使用栈, 什么时候会使用堆? 设计模式:1.单例模式是什么? 它有哪些优缺点? 单例和静态变量有什么区别？单例是线程安全的吗？3.LRU缓存是什么? OC中需要使用到LRU缓存吗? 它是怎么实现的?4.OC中的读写锁是什么? 一般使用在哪些场景? 具体是如何使用的?5.开闭原则是指什么? OC中如何使用开闭原则? iOS:1.Runloop都有哪些mode？分别是怎么使用的?2.runtime的category中实现了跟他一样的一个方法会怎么样？3.KVO实现的原理是什么? 什么情况下使用KVO会导致崩溃?4.autoreleasepool实现原理是什么?5.Swift和OC有哪些明显的差异?6.SDWebImage是什么? 什么时候需要使用到SDWebImage? 有哪些值得学习的SDWebImage的源码?7.图片解码的过程是怎样的?8.指针混淆是什么?9.TagPointer是什么?10.NSString为什么用copy修饰?11.页面路由如何实现? 如何维护一张路由表? 页面是如何进行跳转的? 路由表中的键和值分别是什么？如何根据服务器下发的数据加载页面?12.重写isEqual方法，hash方法的作用是什么? (NSSet)13.performselector和直接调用方法哪个执行速度快?14.为什么一个线程只能有一个runloop?15.子线程的runloop开启后，如果不做任何操作，线程会被杀死吗?16.load方法是在什么时候调用的?17.initialize方法是干嘛用的？是什么时候调用的?18.repeated的NSTimer有哪些性能问题?19.js和OC如何互相调用?20.GCD和NSOperation的区别有哪些? 哪一个的复用性更好? NSOperation的队列可以cancel吗? 里面的任务可以cancel吗?21.block和self是如何形成循环引用的?22.SDWebImage的缓存策略是什么? 是如何从缓存中hit一张图片的；使用了几级缓存；缓存如何满了如何处理，是否要设置过期时间?24.讲讲iOS动画，比如CoreAnimation?25.屏幕上点击一个View，事件是如何去响应的?26.深拷贝与浅拷贝是什么?27.属性有哪些修饰符?28.将一个NSArray赋值给一个copy修饰的NSMutableArray属性，然后尝试向这个可变数组添加对象，会发生什么?30.Extention可以有多个吗？31.Category多个同名方法怎么进行Method swizzing?32.GCD串行队列和并行队列执行顺序分析?33.NSOperator执行顺序分析，maxConcurrent为2或者1两种情况?34.KVO的实现原理，一个类的多次kvo会生成多个新类吗？是直接就对所有的属性都生成新的setter和getter方法吗?37.autoreleasepool原理是什么？如果对一个对象写了多次autorelease，会怎样?38.weak table是用什么数据结构实现的?39.block有哪几种内存类型? 是如何捕获变量的?40.copy和mutableCopy是什么? 他们之间有什么区别?41.@synchronized() 是什么? 它是做什么的? 它的实现原理是什么?42.atomic的实现原理是什么?43.Power()函数是什么?44.block存在的价值是什么? 它和delegate的区别是什么?45._block变量实现原理是什么?47.iOS下载文件下载到一半crash了, 有没有办法等用户回来后再继续下载?48.UIbutton在不改变view大小的情况下扩大点击区域怎么做?49.runtime时添加方法怎么做?","link":"/2024/10/16/iOS/iOS%E9%9D%A2%E8%AF%95%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"title":"Objective-C","text":"OC Objective-C 程序的编译过程通过命令查看某个OC源文件编译过程: clang -ccc-print-phases xxx.m Clang前端处理LLVM后端处理预处理 processing编译 Compilation汇编 Assembly链接 Linking运行时处理 Runtime Handle参考文章 iOS编译过程的原理和应用 Objective-C源文件编译过程","link":"/2024/10/17/iOS/Objective-C/"},{"title":"Convolutional Neural Network","text":"Brief Introduction of Convolutional Neural Network, related architectures and computer vision practice Computer Vision Problems1. Image Classificatione.g. given an image of 64x64x3, say if it’s an image of cats? 2. Object Detectione.g. given an image, detect the objects(cars, pedestrains and motors) in this image 3. Neural Style Transfer Deep Learning on Large Images1. Standard Neural NetworkFor a standard neural network(with all fully-connected layers), an input image of 100010003 may need W[1]: (1000, 3 million) = 3 billion parameters 2. Convolutional Neural NetworkOnly need to train parameters in each filters(kernels), and the number of parameters won’t be affected by the size of input images Convolutional Neural Network1. Some building blocksEdge Detection Standard NN (given all pixels of the input image): early layers may detect edges, then some later layers may detect part of the object, then even later layers detect complete objects Convolutional NN (given the original input image): detect vertical edges detect horizontal edges Edges Detector construct filters (33, 55 or 1*1 matrix, the size of filters usually odd) operation: convolution, represented by ‘*’ in deep learning. one convolution operation: place the filter to the original input image, take the element-wise product and add all resulting numbers, then you got the first number of output 1234567# Convolution Operation:# pythonconv_forward# tensorflowtf.nn.conv2d# KerasConv2D Vertical Edge Detection1234# filter|1 0 -1||1 0 -1||1 0 -1| Horizontal Edge Detection1234# filter| 1 1 1|| 0 0 0||-1 -1 -1| Why can these filters detect vertical/horizontal edges?As for the vertical edge filter, it gets darker vertically from left to right.(In gray images, lager the number is, brighter the pixel is)After running a convolution operation, the filter vertically can make the left part brighter, the right part darker. Some other filters123456789# Sobel filter|1 0 -1||2 0 -2||1 0 -1|# Scharr filter| 3 0 -3||10 0 -10|| 3 0 -3| PaddingUsing convolutions has two downsides (Why we need padding): everytime after convolution, the width and height of the image shrinks pixels on the corners and edges are used much less in the output What’s padding:Before using convolutions, pad the image with additional border. (e.g. original input image size: 66 -&gt; 88) Valid Paddingmeans ‘no padding’ Same Paddingmeans ‘pad the input image to make the size of the output == size of the original input’ StrideNormal Cases: filter moves 1 step on the input image after every calculation (both vertically and horizontally)With Stride: filter moves s steps on the input image after every calculation (both vertically and horizontally) Calculate the size of outputfilter size: f * fpadding: pstride: sinput image size: n * noutput image size: floor((n - f + 2p) / s) + 1 Convolutions over VolumeSingle filterConvolutions on RGB images:input image shape: n_h * n_w * 3(number of channels)filter shape: f * f * 3(number of channels)convolution operation: from matrix element-wise to cube element-wise, each channel of input and filter run convolution, each number of output comes from the sum of all channelsoutput shape: n_h’ * n_w’ Multiple filtersConvolutions on RGB images:input image shape: n_h * n_w * 3(number of channels)filter shape: f * f * 3(number of channels) with n_c‘ filtersconvolution operation: each filter convolves with input image and generate one channel of the output. so if there are c filters, the volume of the output will be coutput shape: n_h’ * n_w’ * n_c’ Convolutional LayersAfter convolving the input image with a set of filters, we add a ‘bias’ to each of the channel(generated by each filter) and apply an activation function(like ReLU) to each of them.Then stack them together, wo got the output after a complete convolutional layer. A complete convolutional layer input image(on behalf of ‘a[i-1]’) a set of filters, each filter has the same volume with input (on behalf of ‘w[i]’ ) bias(constant number, on behalf of ‘b[i]’) activation function(like ReLU, on behalf of ‘g(z[i])’, which z[i] = w[i]*a[i-1] + b[i]) output image(‘a[i]’, which is g(z[i])) Number of parameters in a convolution layer params in each filter: f * f * channels bias for each filter: 1 for m filters in a layer: (f * f * channels + 1) * mSum of the parameters in a convolutional layer: (f * f * channels + 1) * m Pooling LayersPooling layers don’t have parameters, instead, pooling layers use ‘hyper parameters’ such as filter size f and stride s.(no params to learn) Max Poolingchoose the biggest value from each filter area on the input image Average Poolingcalculate the average value of numbers from each filter area on the input image Fully-Connected LayersLike normal layers in standard neural networks, fully-connected layers are usually used after several conv layers in conv networks. Convolutional Neural NetworkHere is a normal cnn structure: 1234567891011121314151617input image | | conv layer: filters, padding, stride vintermediate output image (normally with width and height shrinked and channel expanded) | | conv layer: filters, padding, stride vintermediate output image (normally with width and height shrinked and channel expanded) | | fully-connected layer: some neurons vintermediate output vector | | fully-connected layer: single neuron with softmax activation vclassification result: e.g.say if it's a cat or not Advantages of Conv NetsParameter SharingA feature detector that is useful in one part of the image is probably useful in another part of the image. Sparsity of ConnectionsIn each layer, each output value only depends on a small number of inputs.","link":"/2024/12/15/AI/deep_learning/convolutional-neural-network/"},{"title":"代填坑项目","text":"Todo List~~~ Neural Network Notes K-neighbors and SVM method Relu function multiclass classification (softmax) and numerical round-off error (using linear output and ‘from_logits=True’) Adam algorithm(Adaptive Moment Estimation) CNN (Convolutional Neural Network) forward prop and backward prop vectorization in gradient descent (coding: np.dot(w, x)) python broadcasting: one dimension should equal and the other must be 1","link":"/2024/07/24/AI/machine_learning/%E4%BB%A3%E5%A1%AB%E5%9D%91%E9%A1%B9%E7%9B%AE/"},{"title":"CNN","text":"Delete after finish YOLO algorithm. convolution *(asterisk) filter(kernel) image * filter = new image python: conv_forward, tensorflow: tf.nn.con2d, keras: conv2D edge detection (vertical &amp;&amp; horizontal) filter can distinguish whether the input image is ‘light to dark’ or ‘dark to light’ different numbers used in filters (sobel, Scharr) learn numbers in filter by backprop filter ‘f’ is usually odd(3 x 3, 5 x 5, 7 x 7) padding: pixels on the corners and edges used much less than the middle: problems:1.shrinking output 2.throwing away information from edges of the image padding choices: valid(no padding) and same(pad, so output size is same as input size) stride convolutions: steps the filter moves new output dimension: floor[(n + 2p - f) / s] + 1 convolutions over volumns(3 channels): input image: nnn_channels , filter: ff3, output: 1 volumn(no longer 3) filter ff3 can detect edge of different color(red/green/blue channel) using multiple filters in the same time: output dimension: n_newn_newn_filters types of layers in cnn: Conv layer, Pooling Layer, Fully-Connected Layer Pooling(no params to learn): Max Pooling(usually not use padding) - biggest number, Average Pooling LeNet-5 (conv-pool, conv-pool, fc, fc), AlexNet, VGG-16 Residual NN(skip connection/short cut: residual block) why Residual NN works? identity function is easy for residual block to learn turn a plain NN to a residual NN: add residual blocks(skip connections) 1*1 convolution(one-by-one convolution/network in network) inception network/inception layer: use them all! Question: computation cost (fix: using one-by-one convolution to shrink the channel of the input) MobileNet v1 (depthwise separable convolution: depthwise + pointwise) Depthwise Convolution(number of filters = number of channels, filter size: f * f) Pointwise Convolution / Projection (filter size: f * f * n_channel) MobileNet v2 (2 main changes: 1.add Residual Connection 2.add expansion layer -&gt; bottleneck block) EfficientNet (limited computational resource: how to trade-off between resolution of the input image, depth of the network and width of the layers) Open-Source implementation Transfer Learning (always try when doing computer vision) (freeze layers in others’ projects, the larger dataset you have for your task, the fewer layers you freeze, the more layers you train) data augmentation (Common Used: Mirroring, Random Cropping, Color shifting Less Used: Rotation, Shearing, Local Warping) PCA Color Augmentation implementing distortions during training (have multiple threads to load and implement distortions and pass the results to other threads to train) Tips for doing well on benchmark/competitions (1.Ensembling: train several nets independently and average their outputs 2.Multi-crop at test time: run classifier on multiple versions of test image and average results) object detection: object classification + object localization(landmark detection) = object detection algorithm for object detection: sliding windows. train a CNN to classify entire cars in image, then go sliding windows in original input, pass the crop window image to that CNN to check if there is a car. After go through the entire input image, make the window larger and repeat. problem for sliding windows: 1.huge computational cost. fix: use that algorithm ‘convolutionally’ 2.position of the bounding boxes aren’t too accurate. fix: YOLO algorithm(making grid for input images and label the training data with 8 dimensions: [Pc, bx, by, bh, bw, c1, c2, c3]) YOLO(you only look once) algorithm how to tell if your object detection algorithm is working well? using: intersection over union(IOU): size of intersection(交集) / size of union(并集), correct if Iou &gt;= 0.5(threshold), Iou is a measure of the overlap between two bounding boxes Object Detection Problems: 1.make sure object detection algorithm detect each object only once: non-max suppression: 1.discard all boxes with pc &lt;= 0.6(threshold, means there isn’t any object) 2.while there are any remaining boxes: pick box with the largest pc, output as a prediction, then discard any remaining box with Iou &gt;= 0.5 wit the box you just output as a prediction Object Detection Problems: 2.each of the grid cell can only detect one object(also called ‘overlapping objects’): anchor boxes: pre-define two(or more) different shapes(called ‘anchor boxes’) and reshape the label y (maybe from 8 dimensions to 16 dimensions because of two anchor boxes) YOLO algorithm: put them together: For training set: y is containing two(or more) anchor boxes(two anchor boxes: [pc bx by bw bh c1 c2 c3 pc bx by bw bh c1 c2 c3]) For making predictions: pc == 1 means this anchor box contains the object. Run non-max suppression: choose the highest ‘pc’(probability) predictions, for each class, run non-max suppression to generate final predictions Region Proposals: R-CNN(regions with convolutional neural networks): to run your convolutional classifier on several regions: 1.run segmentation algorithm to determine some blobs(颜色区域) that maybe an object 2.then run convolutional classifier on these blobs. (R-CNN -&gt; Fast R-CNN -&gt; Faster R-CNN) Semantic Segmentation: label every single pixel: semantic segmentation with U-Net(compared to CNN for object recognition, in the U-Net, the width and height first get smaller, then they need to get bigger to blow it back to a full-size image: using transpose convolutions) transpose convolution: set filter to output (not input), use padding and stride to output U-Net:","link":"/2024/12/09/AI/deep_learning/CNN/"},{"title":"Kaggle做题记录和题目索引","text":"~ Titanic - Machine Learning from Disaster 预测泰坦尼克游客是否能够幸存题目地址 House Prices - Advanced Regression Techniques 预测房屋售价题目地址","link":"/2024/07/06/AI/machine_learning/kaggle/Kaggle%E5%81%9A%E9%A2%98%E8%AE%B0%E5%BD%95%E5%92%8C%E9%A2%98%E7%9B%AE%E7%B4%A2%E5%BC%95/"},{"title":"kaggle新手入门指北","text":"Kaggle小白快速上手指北~~~ 准备工作 比赛选择上来先筛选出新手模块的competition, 因为我本人是新手, 并且想练习课程中学到的知识, 所以就从简单的开始了~~ 了解比赛信息Description 描述信息根据”Description”模块可以快速了解题目背景, 因为kaggle中的题目(我目前接触到的)都与现实紧密结合, 所以我认为多了解题目背景有助于日后的工作. Data Description 数据描述我们可以切换到”Data”tab下, 这里会罗列出本场竞赛提供的数据信息, 如训练集, 测试集, 提交样例等等. 熟悉ACM(ICPC)的朋友应该对这些并不陌生. 翻到页面最下方可以下载所有的数据文件, 本地用”Pycharm”打开就可以详细地浏览啦~ Evaluation 模型评估就像算法竞赛, 我们了解了题目, 熟悉了输入数据后, 最重要的是要看看怎么得分~切回”Overview”tab后下翻, 可以看到”Evaluation”模块, 这里介绍了本场竞赛的目标, 例如预测每一栋房子的售价; 提交的评分标准, 例如这里是按照RMSE(均方根误差); 以及提交文件的正确格式. 添加比赛到Collection在比赛详情页右上角”···”处添加该比赛到Collection, 这样有一个好处是在提交时更方便选择Notebook(后面会创建), 并且起到收纳的作用, 这样你可以对于多种思路的Notebook实现都收纳在该Collection下.这样就能看到刚才创建的Collection了. 创建Notebook我在Kaggle上的比赛都是通过”Notebook”完成的, Notebook是一个类似jupyter的工具, 可以在里面一边通过markdown梳理思路, 描述建模过程, 一边通过内嵌的python编译器来编码实现预测过程. 创建后会在新页面开启这个Notebook, 可以在左上角重新命名, 我这里命名成了”notebook_test_1”. 还是返回Your Work页面, 刷新后会发现刚才创建的新Notebook. 点击最右边的”···”并在二级菜单把它添加到刚才我们创建的Collection, 这样你的新Notebook就收纳在你创建的本场比赛对应的Collection中了. 至此, 我们就可以开始愉快地Kaggle之旅了~","link":"/2024/07/08/AI/machine_learning/kaggle/kaggle%E6%96%B0%E6%89%8B%E5%85%A5%E9%97%A8%E6%8C%87%E5%8C%97/"},{"title":"Images Classifier","text":"Classic networks like LeNet-5, AlexNet and VGG; Architectures like ResNet and Inception Net to improve performance of CNNs; MobileNets to allow mobile devices to run apps of classifier systems; Transfer Learning and Data Augmentation to start your system faster and make your classifier stronger. Classic NetworksLeNet-5 UsedClassify hand-write digit TrainedGray scale images (32 * 32 * 1) Params60k PaperGradient-based learning applied to document recognition (part II) Feature as going deeper in the network, n_H, n_W goes down, n_C goes up structure: conv-pool-conv-pool-fc-fc-output using average pooling layers, and sigmoid/tanh rather than ReLu functions in the hidden layers AlexNet UsedImage Recognition TrainedRGM images (2272273) Params60m PaperImageNet classification with deep convolutional neural networks Feature using ReLu function multiple GPUs (GPU communicate with each other) Local Response Normalization (choose a position in a image and normalize every same position among all channels) VGG - 16 UsedTrainedRGM images (2242243) Params138m PaperVery deep convolutional networks for large-scale image recognition Feature fixed filters: CONV = 3 * 3 filter, s = 1, same convolution; Max-Pool = 2 * 2, s = 2 the n_H and n_W shrink double (after every pool layer) or n_C grows double (after every conv layer) Residual Network For very deep networks, there are usually problems like gradient vanishing and gradient explosion. With ResNets, we can train very deep networks. Residual Block A residual block contains some extra layers and a skip connection. (for example below, 2 fully-connected layers and 1 skip connection) A residual network is a neural network contains multiple residual blocks. 1234567a[l] ---&gt; Linear ---&gt; ReLu ---&gt; a[l+1] ---&gt; Linear ---&gt; ReLu ---&gt; a[l+2] (main path) | ^ | | pass 'a[l]' here before ReLu ---------skip connection / short cut-----------Before: a[l+2] = g(z[l+2)After Adding Residual Block: a[l+2] = g(z[l+2] + a[l]) PaperDeep residual networks for image recognition Features compared to plain networks, ResNet allows us to have a reasonable training error even we have many layers. Identity function is easy for Residual Block to learn. (That’s why adding more layers to the network doesn’t hurt the performance) usually use ‘same convolutions’ in ResNets to make a[l] and z[l+2] have the same dimension. (If not, add an extra matrix ‘Ws’ to a[l]) we can turn a plain net into a res net by adding residual blocks. 1*1 Convolutions Network one-by-one convolution is like having a fully-connect neural network that apply to each position of the input channels. PaperNetwork in network Features use one-by-one convolutions to shrink the number of volume Inception Network (‘Google Net’: Inception V1) In generally speaking: Instead of needing to pick any size of the filters or pooling, we do them all and concatenate all the outputs. Let the network learn whatever params it wants to use. Inception Network: Neural network puts a lot of inception modules together. PaperGoing deeper with convolutions Inception Module (inception blocks)1234567 --------------------------------&gt; 1 * 1 CONV ---------| | |Previous |------------&gt; 1 * 1 CONV ------&gt; 3 * 3 CONV ---------| ChannelActivation ------ |----&gt; Concat |------------&gt; 1 * 1 CONV ------&gt; 5 * 5 CONV ---------| | | ----------&gt; MaxPool(Padding) ---&gt; 1 * 1 CONV ---------| Feature Computational Cost: Use 1*1 convolution to shrink the channel first, then do regular convolutions. Have several side branches that also predict like the output layer (ends with a softmax function), this has a regularizing effect and reduces the overfitting. MobileNet V1 Depthwise Separable Convolution (Building Block of MobileNets)Depthwise Convolutionn_c filters, each filter(size: f * f * 1) convolve with each channel of input, the channel of output will be the same as input Pointwise Convolution (Projection)n_c’ filters, each filter(size: 1 * 1 * n_c) convolve with the whole input, the channel of output will be n_c’ PaperMobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications Feature Low computational cost at deployment: MobileNets cost usually $\\frac{1}{n_c’} + \\frac{1}{f * f}$ times of that in normal convolutions, which is about 10 times cheaper. Useful for mobile and embedded vision applications MobileNet V2 PaperMobileNetV2: Inverted Residuals and Linear Bottlenecks Bottleneck Block123456789 --------------------------------- Residual Connection ------------------------------- | | | (channel expands) (channel shrinks) v--------&gt; n * n * 3 --------&gt; n * n * 18 --------&gt; n * n * 18 ----------&gt; n * n * 3 ---------&gt; ^ ^ ^ | | | 1 * 1 * 3 Depthwise 1 * 1 * 18 Expansion (same convolution) Pointwise/Projection (18 filters) (18 filters) (3 filters) Why using Bottle Block? By using ‘Expansion’, it lets the neural network to learn a richer function by increasing the representation. (From n * n * 3 to n * n * 18) Memory is limited for mobile devices, so bottleneck block uses ‘Pointwise/Projection’ operation to shrink the representation before pass it to next block. (When passing, the memory needs to pass these values reduced.) EfficientNet How to automatically increase or scale the size of the neural network on different devices? ‘Good Trades off‘ between image resolution, depth of the network and width of the layers. PaperEfficientNet: Rethinking Model Scaling for Convolutional Neural Network Transfer Learning How to create a classifier for myself if I don’t have much data? Using Transfer Learning! In Computer Vision, transfer learning is one thing that you should almost always do.(Unless you have an exceptionally large data set) Freeze LayersWhen you have Little Data Download a open-sourced implementation of neural network(with its weights), replace the softmax and output layer with your own layers and freeze the other layers. Train your own ‘softmax’ and ‘output’ layers. When you have Large DataFreeze fewer layers and train the later layers (Initialize the weights of later layers and run gradient descent on them. / Blow away these layers and create you own layers.). When you have A Lot of DataChange the ‘softmax’ and ‘output’ layers, and train the whole network. Neat Trick to Speed up TrainingSince you froze several layers and didn’t want to train them: pre-compute the last frozen layer for all training sets and save the results to disk. So you just need to train a shallow softmax classifier instead of a big one. Fast Reason: You don’t need to calculate the frozen layers everytime you train the network. Data Augmentation Common augmentation methods (distortions) Mirroring Random Cropping Color shifting: Add different distortions to RGB channels. (color distortion algorithm: PCA Color Augmentation-Principles Component Analysis) Less using methods Rotation Shearing Local warping Hyper params in Data AugmentationA good way is to use others’ trained hyper params in their network. Implementing Distortions123456789101112implementing distortions during training: distortionshard disk ----- data1 -------&gt;-------- new data1 ------ ---- | | | | --- load --- ---------&gt; Training ---- | distortions | ----- data2 -------&gt;-------- new data2 ------ CPU/GPU -------- |----&gt; can run in parallel CPU threads -------------------------------------------- (loading data and implementing distortions) Tips for Benchmarks and Competitions Ensembling (maybe 1% or 2% better, needs much memory): Train several networks independently and average their outputs.(like ‘tree ensemble’) Multi-crop at test time (a little bit better, don’t need much memory): Run classifier on multiple versions of test images and average results. (10-crop) Tips for Building a Computer Vision Practical System Use architectures of networks published in the literature. Use open source implementation if possible. Use pretrained models and fine-tune on your dataset. If you have huge data or need to invent a system by yourself, you can make a system from scratch. Reference https://www.coursera.org/learn/convolutional-neural-networks/home/week/2","link":"/2024/12/27/AI/deep_learning/image_classifier/"},{"title":"Face Recognition","text":"Face Recognition Face Recognition Face Verification1:1 problem: Input: image, name/ID of a certain person Output: if input image is that specific person Face Recognition1:K problem: Input: image Output: if input image is one of the K persons / not recognized Note: face verification model can be used to face recognition problem unless it has a very high accuracy. if the former has 1% chance to make a mistake, then it will be K% chance while in recognition task. One-Shot LearningLearning from one example to recognize the person again. For normal CNN, we don’t have that much image data. And every time add a new person to system, we don’t want to train the network again. Learn a similarity function ‘d’d(img1, img2) = difference between img1 and img2 If d(img1, img2) ≤ τ: img1 and img2 are same person &gt; τ: img1 and img2 are not same person Siamese NetworkInstead of using the ‘softmax’ output layer as a classifier learned before, we use a fully-connected layer deeper in the network. The vector of this FC layer is called ‘encoding of input image1’, f(image1). The difference between img1 and img2 is presented by ‘Euclidean Distance’, which is $ \\ d(\\mathbf{f(img1)}, \\mathbf{f(img2)}) = \\sqrt{\\sum_{i=1}^n (f(img1)_i - f(img2)_i)^2} ] $ Goal of Learning Siamese Network Params of network represent the encoding of $ f(img_i) $ Learn params so that: If $img_i$, $img_j$ are the same person, $d(img_i, img_j)$ is small ; If $img_i$, $img_j$ are different person, $d(img_i, img_j)$ is large. Triplet Loss FunctionTriplet: should always watch 3 images: Anchor, Positive (same person with anchor) and Negative (different person with anchor) Target: difference between d(A, P) and d(A, N) is greater or equal to a margin (-α), which is: $d(A, P) + α - d(A, N) ≤ 0$ Loss Function: $L(A, P, N) = max(d(A, P) + α - d(A, N), 0)$ Cost Function: $J = \\sum_{i=1}^n (L(A, P, N))$ PaperFaceNet: A unified embedding for face recognition and clustering. Face Verification and Binary ClassificationPrevious: Use ‘Triplet’ loss function to train the params in ConvNet Binary Classification: Take two images ($ x^i, x^j $) from new input and database, separately into the Siamese Network Embed their encodings ($ f(x^i), f(x^j) $) into a logistic regression unit Make a prediction. (1: same person, 0: different person) Procedure of Logistic Unit$\\begin{aligned}\\hat{y} = \\text{sigmoid}\\left(\\sum_{k=1}^n w_k \\cdot \\left|{f(x^i)}_k - {f(x^j)}_k\\right| + b\\right),\\ n = num\\ of\\ features\\ in\\ encoding\\end{aligned}$ where$\\left|{f(x^i)}_k - {f(x^j)}_k\\right| = \\frac{ \\left({f(x^i)}_k - {f(x^j)}_k \\right)^2 }{ {f(x^i)}_k + {f(x^j)}_k }$, which is called ‘chi square norm’ Pre-Compute the encodings for Database ImagePre-compute the encodings for all database images, when a new image comes, we can just compute its encoding and embed it with the pre-computed encodings to make a prediction Not only used in binary face verification, but also in triplet loss function. PaperDeepFace closing the gap to human level performance.","link":"/2025/01/11/AI/deep_learning/face_recognition/"},{"title":"Object Detection","text":"Algorithms for object detection. Object DetectionObject detection contains ‘Object Localization’ and ‘Landmark Detection’. Object Localization Image classification (if there is a car in image) Image classification with localization (label the car in image and draw a boundary box of the car) Detection (detect and localize all cars in the image) Classification with LocalizationNetwork for classification: predict the class after softmax layer. Network for classification and localization: change the output layer to contain 4 more numbers, ‘bx, by, bh, bw’. (add a bounding box) Example of Defining the Target Label y (one object) pedestrian car motorcycle background 12345678 [ Pc: is there any object? 1: one object, 0: no objects (when Pc is 0, other nums make no sense, don't care) | bx: mid-point of the bounding box^ | by: mid-point of the bounding boxy = | bh: height of the bounding box | bw: width of the bounding box | C1: is the object class 1? | C2: is the object class 2? [ C3: is the object class 3? Landmark DetectionIf you’d like your neural network to output important points and their coordinates, which were called ‘landmarks’. Example of Defining the Target Label y (landmark detection)Detect 4 landmarks of the eyes on a person’s face: l1x, l1y (coordinate of left corner of left eye) l2x, l2y (coordinate of right corner of left eye) l3x, l3y (coordinate of left corner of right eye) l4x, l4y (coordinate of right corner of right eye) 123456789 [ Pc: is there a face? 1: yes, 0: no | l1x | l1y^ | l2xy = | l2y | l3x | l3y | l4x [ l4y Application for Landmark Detection AR augmented reality filters: like putting a crown on the face key building block for computer graphics People pose detections Notice of LandmarksLandmarks should be consistent through all data sets. (e.g.: landmark 1 should always be left eye and landmark 2 shou always be right eye) Object DetectionTo do object detection, you need a conv net to recognize objects and an algorithm called ‘Sliding Windows’. One Object Detection in Each CellSliding Windows detection Pick a small window size, start from left top corner, pass this rectangular window image to your ConvNet and make a prediction. Then slide the window a little bit over to right and feed that new region image into your ConvNet. Keep going until you slide the window through the entire input image. Pick a larger window size, repeat steps above. Convolutional Sliding WindowsBiggest disadvantage of sliding window algorithm: Computational Cost. (Much duplicated computations) Position of bounding boxes isn’t too accurate. Method to fix the computational cost is called ‘Convolutional Sliding Windows’. Turn FC layer into convolutional layers change each FC layer into n filters (n refers to the number of units in this FC layer) the size of each filter matches the size of the prior output. Convolution implementation of sliding windows Instead of feeding every region of the input into the ConvNet, you feed the entire original input image into ConvNet. With turning FC layers into conv layers, every number of the final output represents the result of the relevant position window. Method to fix the position of bounding box is called ‘YOLO algorithm’. YOLO algorithm Put a grid on the input image. (n * n grid) For each grid cell, after running the object classification and localization model, we get an output label y. (8-dimensions) YOLO algorithm: take the midpoint of the object and assign the object to the grid cell which contains that midpoint. Define the Target y (YOLO algorithm)12345678910 [ Pc | bx: mid-point of the bounding box [left top of the grid cell: (0,0), right bottom of the grid cell: (1, 1)]^ | by: mid-point of the bounding boxy = | bh: ratio between the bounding box's height and the grid cell's height | bw: ratio between the bounding box's width and the grid cell's width | C1 | C2 [ C3 bx and by must be between 0 and 1, bh and bw could be between 0 and 1 Notice of YOLO YOLO is like classification and localization task before. Using convolutional implementation, rather than feed each single grid cell separately into the ConvNet. Works for real-time object detection. PaperYou Only Look Once: Unified real-time object detection. (One of the harder to read) Intersection Over UnionIoU could be used in both evaluating object localization and object detection algorithm. Evaluate Object LocalizationIntersection: size of the intersection between your bounding box and the ground truth box Union: size of the union between your bounding box and the ground truth box IoU = Intersection / Union, ‘Correct’ if IoU ≥ 0.5 (could also be ‘0.6’, ‘0.7’…) Use in Object Detecting AlgorithmsIoU is also used in ‘non-max suppression’ and ‘anchor boxes’ algorithms. Non-max SuppressionDuring the classification and localization task, it’s common that the same object may be detected more than once. Since there are many gird cells say that they found an object. That’s the reason we need non-max suppression. Steps of Non-max Suppression (Detecting Single Object) discard all boxes with probability &lt;= 0.6. pick the box that has the highest probability (kind of ‘Pc’), which means ‘the most confident one to have an object there‘. And this is one prediction. discard any other boxes that have a high ‘IoU’ (like IoU &gt;= 0.5) with the selected one above. if there are any remaining boxes, repeat from step 2. Notice of Non-max Suppression To detect n objects, you need to run non-max suppression n times. Multi Objects Detection in Each CellThere are more than one objects in the same area, which means multi mid-points in one cell. Anchor BoxesPre-defined multi different anchor boxes, called anchor boxes and anchor box shapes. Each object is assigned to the grid cell that contains object’s midpoint and anchor box with highest IoU. Compared to ‘single object detection’ before, the object will not only be assigned to the gird cell by location of its midpoint, but also assigned to the appropriate anchor box which has the highest IoU with this object. The object will be encoded in (grid cell, anchor box) in target label. Example of Defining the Target Label y (two anchor boxes)12345678910111213141516 [ Pc | bx: mid-point of the first bounding box | by: mid-point of the first bounding box | bh: height of the first bounding box | bw: width of the first bounding box | C1 | C2^ | C3y = | Pc | bx: mid-point of the second bounding box | by: mid-point of the second bounding box | bh: height of the second bounding box | bw: width of the second bounding box | C1 | C2 [ C3 Notice of Anchor Boxes Can’t handle well in case that when you have two anchor boxes and three objects in one grid cell. Can’t handle well in case that when you have two objects of similar shape’s anchor box in one grid cell. While choosing shapes of anchor boxes, the automatically and stereotypically representative method is ‘K-means’. YOLO with Components AboveHere is the relatively complete YOLO algorithm: put a grid on the input image and run convolution on the entire input image for each grid cell, we can get a target y with several anchor boxes use non-max suppression n times for n classes (car, motorcycle, pedestrian..), get the final output Region proposalTry to just pick few regions that make sense (contain objects) to run convNet classifier. Segmentation Algorithm: turn image into many blobs. R-CNNPropose regions. Classify proposed regions one at a time. Output label + bounding box. Fast R-CNNPropose regions. Use convolutional implementation of sliding windows to classify all proposed regions. Faster R-CNNUse convolutional network to propose regions. Semantic SegmentationLabel every single pixel to different classes. Difference between Object Detection and Semantic Segmentation One of the usage is for self-driving car tasks to figure out which pixels are safe to drive. Segmentation with U-Net Instead of giving a class label and coordinates specifying bounding box, segmentation algorithm (U-Net) outputs a whole matrix of labels. Transpose ConvolutionNormal Convolution: shrink the height, width and expand the channel Transpose Convolution: expand the height, width and shrink the channel U-Net Reference: https://www.coursera.org/learn/convolutional-neural-networks/home/week/3","link":"/2025/01/03/AI/deep_learning/object_detection/"},{"title":"Useful Methods in Kaggle","text":"methods in Kaggle~ Plotting During a competition, there must be a number of features and some of them might make more influence on the target value than others. So It’s very useful to plot each feature versus target value. Assume that we’re going to draw a image below: We can write these code in python: 123456fig,ax=plt.subplots(row_num, column_num, figsize=(plot_weight, plot_height), sharey=True)for i in range(len(ax)): ax[i].scatter(X_train[:,i], y_train) ax[i].set_xlabel(X_features[i])ax[0].set_ylabel(&quot;Price (1000's)&quot;)plt.show() Here are some explanations: fig: the container of all imgs(there are four in the img above) ax: the array contains all imgs(e.g., ax[0] refers to img one, ax[1] refers to img two, …) sharey: “true” means all imgs share Y-axis scale ax[i].scatter(X_train[:,i], y_train): plot scatter chart for i’th img, using the i’th feature for X-axis and target value in dataset for Y-axis ax[i].set_xlabel(X_features[i]): set the label of X-axis with i’th feature’s name ax[0].set_ylabel(“Price (1000’s)”): set the label of Y-axis with target value’s name, which in the example is “Price (1000’s)”","link":"/2024/07/10/AI/machine_learning/kaggle/useful_methods_in_Kaggle/"},{"title":"Terms in programming","text":"– arguments: 实参, 调用函数时传入的参数 parameters: 形参, 定义函数时包含的参数","link":"/2024/12/04/python/terms_in_python_programming/"},{"title":"Scikit Learn Implementation","text":"记录scikit learn库的使用~~~ Logistic Regression Loading Dataset1234import numpy as npX = np.array([[0.5, 1.5], [1,1], [1.5, 0.5], [3, 0.5], [2, 2], [1, 2.5]])y = np.array([0, 0, 0, 1, 1, 1]) Fit the Model1234from sklearn.linear_model import LogisticRegressionlr_model = LogisticRegression()lr_model.fit(X, y) Make Predictions123y_pred = lr_model.predict(X)print(&quot;Prediction on training set:&quot;, y_pred) Evaluate Accuracy1print(&quot;Accuracy on training set:&quot;, lr_model.score(X, y))","link":"/2024/07/12/python/scikit_learn/"},{"title":"Neural Style Transfer","text":"Neural Style Transfer in deep learning Neural Style TransferUse a ‘Content’ image C and a ‘Style’ image S to generate a new image G, which has C’s content and S’s style. What are Deep ConvNets learning?One way we can do is visualizing. From shallow layers to deep layers, pick a unit and find the image patches that maximize the unit’s activation. Then repeat for other units. PaperVisualizing and understanding convolutional networks receptive field Cost Function$J(G) = α \\cdot J_{content}(C, G) + β \\cdot J_{style}(S, G)$ $J_{content}(C, G)$ means how similar is the content of image G to that of the image C$J_{style}(S, G)$ means how similar is the style of image G to that of the image C $J_{content}(C, G)$ For using hidden layer l to compute content cost. Use a pre-trained ConvNet. (E.g., VGG network). Let $a^{[l](C)}$ and $a^{[l](G)}$ be the activation of layer l on the images C and G. If $a^{[l](C)}$ and $a^{[l](G)}$ are similar, C and G have similar content. $J_{content}(C, G) = ||a^{[l](C)} - a^{[l](G)}||^2,\\ it’s\\ L2\\ Norm\\ between\\ a^{[l](C)}\\ and\\ a^{[l](G)}$ $J_{style}(S, G)$PaperA neural algorithm of artistic style. Images on slide generated by Justin Johnson.","link":"/2025/01/13/AI/deep_learning/neural_style_transfer/"},{"title":"Linear Regression (线性回归模型)","text":"linear regression model~ 线性回归模型(Linear Regression) 线性回归模型可以根据一些特征值(feature x)数据, 计算一个可能的结果(预测), 这个结果是无限多个数中的一个. 例如根据房屋个数, 房屋面积, 花园面积和房屋建成年份等特征值进行房价预测等. In a word, linear regression predicts sequential values. 模型表示$$f_{\\vec{w},b}(\\vec{x}) = \\vec{w} \\cdot \\vec{x} + b$$ 其中 $f(\\vec{x})$ 是模型预测结果(也称作 $\\hat{y}$ ), $\\vec{x}$ 是输入模型的特征值. 而 $\\vec{w}$ 和 b (weight and bias)是模型的两部分参数. 选择适当的 $\\vec{w}$ 和 b 能使模型更好地对特征值进行拟合, 从而获得更准确的预测结果. 这里 $\\vec{x}$ 和 $\\vec{w}$ 使用向量表示. 对于特征值来说, 大部分情况下会有很多个维度的特征值(如上面房屋的多个信息), 因此对应地, 每个特征值都需要一个w系数来调整该特征值在整个模型中的权重. b表示一个偏差, 它不受特征值集合的维度影响, 因此是一个常数. 代价函数(cost function)为了使模型的预测结果尽可能准确或者符合预期, 我们需要尽可能找到一组最合适的 $\\vec{w}$ 和 b. 对于已有数据集, 假设模型的预测结果为 $\\hat{y}^{(i)}$ , 而实际值为 $y^{(i)}$ , 预测结果和实际值的差距为 $y^{(i)}$ - $\\hat{y}^{(i)}$ , 即建模误差(modeling error) 而代价函数的大致定义就是: 对于整个输入集, 所有建模误差的平方和. 即$$J = \\frac{1}{2m} \\sum_{i=1}^{m} \\left( \\hat{y}^{(i)} - y^{(i)} \\right)^2$$其中, J是关于 $\\vec{w}$ 和 b 的函数, 而 $\\hat{y}$ 就是 $f_{\\vec{w},b}(\\vec{x})$. 梯度下降(gradient descent)我们的目标是找到 $\\vec{w}$ 和 b 使得代价函数J最小. 一种自动化通过程序实现的方式称作“梯度下降”. 课程中举例: 想象一下你正站立在山的这一点上，站立在你想象的公园这座红色山上，在梯度下降算法中，我们要做的就是旋转360度，看看我们的周围，并问自己要在某个方向上，用小碎步尽快下山。这些小碎步需要朝什么方向？如果我们站在山坡上的这一点，你看一下周围，你会发现最佳的下山方向，你再看看周围，然后再一次想想，我应该从什么方向迈着小碎步下山？然后你按照自己的判断又迈出一步，重复上面的步骤，从这个新的点，你环顾四周，并决定从什么方向将会最快下山，然后又迈进了一小步，并依此类推，直到你接近局部最低点的位置。 梯度下降的算法公式:repeat simultaneously until converge: {$$w = w - \\alpha \\frac{\\partial}{\\partial w} J(w, b)$$$$b = b - \\alpha \\frac{\\partial}{\\partial b} J(w, b)$$} 其中 $\\alpha$ 是学习率 (learning rate), 表示每一次梯度下降的“步长”(即w和b在某个下降的方向上减少的程度, 学习率越大则w和b下降越快, 反之则越慢) 上下等式的 $\\partial J(w, b)$ 是指代价函数J分别对 w 和 b 求偏导, 其结果应该是:$$\\frac{\\partial}{\\partial w} J(w, b) = \\frac{1}{m} \\sum_{i=1}^{m} \\left( \\hat{y}^{(i)} - y^{(i)} \\right) x^{(i)}$$$$\\frac{\\partial}{\\partial b} J(w, b) = \\frac{1}{m} \\sum_{i=1}^{m} \\left( \\hat{y}^{(i)} - y^{(i)} \\right)$$ 梯度下降的执行:给定一组w和b的初始值, 将下面的偏导结果运用到梯度下降公式中, 并同时更新w和b的值直到收敛(代价函数值随着每次梯度下降的执行不再减小并左右微小跳动). 线性回归模型的代价函数J是关于w和b的二次函数且是一个凸函数, 所以在其定义域内有且仅有一个最小值, 即全局最小值. 所以我们指定一组初始的w和b, 经过梯度下降算法之后总能找到代价函数的最小值. 线性回归模型和梯度下降算法经过上面的学习, 我们便掌握了一种机器学习预测模型(线性回归模型)和一种机器学习模型训练算法(梯度下降算法). Reference https://www.coursera.org/learn/machine-learning/lecture","link":"/2024/07/08/AI/machine_learning/notes/linear_regression/"},{"title":"Logistic Regression (逻辑回归模型)","text":"logistic regression model~ Logistic Regression Compared with linear regression, logistic regression is used to solve questions which only have limited possible answers. For example, if an email is spam or not, if a tumour is malignant or benign and so on. Logistic regression predicts discrete values. Sigmoid Function For classification problems, we also starts by using the linear regression model, $f_{\\vec{w},b}(\\vec{x}) = \\vec{w} \\cdot \\vec{x} + b$ . However, we would like the predictions of our classification model to be between 0 and 1 since our output variable 𝑦 is either 0 or 1. So here we’re introducing “sigmoid function“ which maps all input values to values between 0 and 1.$$sigmoid: g(z) = \\frac{1}{1 + e^{-z}}$$ Logistic Regression A logistic regression model applies the sigmoid to the familiar linear regression model:$$f_{w,b}(\\mathbf{x}^{(i)}) = g(\\mathbf{w} \\cdot \\mathbf{x}^{(i)} + b)$$ where$$g(z) = \\frac{1}{1 + e^{-z}}$$ Decision Boundary We now know the answers of classification problems are discrete, and logistic regression models predict values range from 0 to 1 after using sigmoid function. But how do we get the final predict, like a tumour is malignant or benign? We can’t give a predict like, ‘this tumor has 75% chance to be benign’. It must be a certain answer. So, we need to make decision boundary. Assume that ‘y = 1’ represents the positive result, like ‘benign’, and ‘y = 0’ refers to the negative result, ‘malignant’. We can use a threshold = 0.5 to split the values of the model as below: if $f_{w,b}(x) &gt;= 0.5$ , y = 1if $f_{w,b}(x) &lt; 0.5$ , y = 0 According to the logistic regression description above, $f_{w,b}(x) = 0.5$ means $g(z) = 0.5$, then we can get the value of $z$. The function $z = \\mathbf{w} \\cdot \\mathbf{x} + b$ is just the decision boundary under a threshold of 0.5. Cost Function When we implement the cost function of linear regression to logistic regression, it turns out to be a non-convex function and not suitable for logistic regression. So we are using a new function called ‘Logistic Loss Function’. Loss Function Loss is a measure of the difference of a single example to its target value. Cost is a measure of the losses over the entire training set. For a single data point: Cost FunctionTo form the cost function, we combine the losses.$$J(w, b) = \\frac{1}{m} \\sum_{i=0}^{m-1} \\left[ loss(f_{w,b}(\\mathbf{x}^{(i)}), y^{(i)}) \\right]$$ Gradient Descent in Logistic Regression Logistic regression uses almost the same pattern as linear regression, except the function “f”.$$\\frac{\\partial}{\\partial w} J(w, b) = \\frac{1}{m} \\sum_{i=1}^{m} \\left( f^{(i)} - y^{(i)} \\right) x^{(i)}$$$$\\frac{\\partial}{\\partial b} J(w, b) = \\frac{1}{m} \\sum_{i=1}^{m} \\left( f^{(i)} - y^{(i)} \\right)$$ where $ f = g(z) = sigmoid(z), z = \\vec{w} \\cdot \\vec{x} + b $ Summary From this lesson, we now learn a new regression model called ‘Logistic Regression’ and how to implement gradient descent on it. It’s used to solve classification problems. We also learn a method called ‘Regularization’ and add the regularization term to cost function for both linear and logistic regression, in order to solve overfitting problem.","link":"/2024/07/11/AI/machine_learning/notes/logistic_regression/"},{"title":"Neural Network Model (神经网络模型)","text":"Neural Network Model~~~ Why do we need Neural Network? There is a weakness in both linear regression and logistic regression: the model needs to do a large amount of calculation when there are too many input features. That’s why we need neural network. What’s Neural Network? Neural Network is an algorithm to simulate the way human brain learns.","link":"/2024/07/13/AI/deep_learning/neural_network_model/"},{"title":"Optimization for Gradient Descent and Learning Algorithm","text":"Notions about gradient descent. Optimizing Learning Algorithm Feature Engineering (特征工程)Use intuition to create new features, by combining and transforming the original ones. Polynomial RegressionUse not only $x$, but also $x^2, x^3, \\sqrt{x}$ etc. Gradient Descent Convergence Plot a “Learning Curve” graphPlot a graph of cost function J after each iteration (after gradient descent) on the y-axis and times of iteration on the x-axis. Watch if the learning curve is decreasing after every iteration. J ever increased: $\\alpha$ is too large or any bugs Automatic Convergence Test with $\\epsilon$Let $\\epsilon$ be $10^{-3}$. If J decreases by $\\leq \\epsilon$ in one iteration, convergence! Disadvantage: $\\epsilon$ is hard to choose Choose the Learning RateTry a series numbers: from $\\alpha$ = 0.001, plot the learning curve graph. multiple $\\alpha$ by three (e.g., 0.001 -&gt; 0.003 -&gt; 0.01 -&gt; 0.03), repeat step 1 to find a suitable $\\alpha$. Feature Scaling (特征缩放) When we face the problem of multi-dimensional features, we need to ensure that these features have similar ranges, which will help the gradient descent algorithm converge faster. One way to do this is called “Feature Scaling”. 1. Mean Normalization (均值标准化)$$x_i := \\frac{x_i - \\mu_i}{\\text{max} - \\text{min}}$$ $\\mu_i$ refers to the mean of all the values for feature (i) 2. Z-score Normalization$$x_j^{(i)} = \\frac{x_j^{(i)} - \\mu_j}{\\sigma_j}$$ µ𝑗 (miu) is the mean of all the values for feature (j). 𝜎𝑗 (sigma) is the standard deviation of feature (j), which is calculated by $𝜎 = \\sqrt{\\frac{\\sum_{i=1}^N (x_i - µ)^2}{N}}$ Overfitting and Regularization (过拟合和正则化)OverfittingMake too many efforts (use polynomial patterns) to train the model under training dateset will cost “overfitting”, which means the model could do well in training dataset, but no good in new dataset. High Bias and High VarianceHigh bias (underfit): model doesn’t fit training set well. High Variance (overfit): model fits training set extermely well, but seems won’t generalize to new data well. Reduce Overfitting Collect more training data. Try to avoid using so many polynomial features. Select features to include / exclude (feature selection): useful features could be lost all features + insufficient data -&gt; overfit Regularization RegularizationTo fix overfitting, we use a technique called “regularization”. Regularization encourages gradient descent to minimize the size of the parameters, which avoid the polynomial features to make an overly large effect. regularization term:$$\\frac{\\lambda}{2m}\\sum_{j=0}^{n-1} w_j^2,\\ \\lambda \\ is \\ regularization parameter$$ The parameter b will usually not be regularized. Choose good values for $\\lambda$ Regularization for Linear Regression$$J(\\mathbf{w},b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})^2 + \\frac{\\lambda}{2m} \\sum_{j=0}^{n-1} w_j^2 \\tag{1}$$where:$$f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = \\mathbf{w} \\cdot \\mathbf{x}^{(i)} + b \\tag{2}$$ Regularization for Logistic Regression$$J(\\mathbf{w},b) = \\frac{1}{m} \\sum_{i=0}^{m-1} \\left[ -y^{(i)} \\log\\left(f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) - \\left( 1 - y^{(i)}\\right) \\log \\left( 1 - f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) \\right] + \\frac{\\lambda}{2m} \\sum_{j=0}^{n-1} w_j^2 \\tag{3}$$where:$$f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = sigmoid(\\mathbf{w} \\cdot \\mathbf{x}^{(i)} + b) \\tag{4}$$","link":"/2025/01/16/AI/machine_learning/notes/optimizing_gradient_descent/"},{"title":"Model Evaluation","text":"Evaluate a model and decide what to do next. Model EvaluationTrain Test SplitSplit the dataset to: 70% for training and 30% for testing. Train/test Procedure for Linear RegressionFit params by minimizing const function J (contains regularization term)$$J(\\mathbf{w},b) = \\frac{1}{2m_{train}} \\sum\\limits_{i = 1}^{m_{train}} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})^2 + \\frac{\\lambda}{2m_{train}} \\sum_{j=1}^{n} w_j^2$$ Compute Test Error:$$J_{test}(\\mathbf{w},b) = \\frac{1}{2m_{test}} \\sum\\limits_{i = 1}^{m_{test}} (f_{\\mathbf{w},b}(\\mathbf{x_{test}}^{(i)}) - {y_{test}}^{(i)})^2$$ Compute Train Error:$$J_{train}(\\mathbf{w},b) = \\frac{1}{2m_{train}} \\sum\\limits_{i = 1}^{m_{train}} (f_{\\mathbf{w},b}(\\mathbf{x_{train}}^{(i)}) - {y_{train}}^{(i)})^2$$ $J_{train}(\\mathbf{w},b)$ will be low, and $J_{test}(\\mathbf{w},b)$ will be high. Train/test Procedure for Logistic RegressionFit params by minimizing const function J (contains regularization term)$$J(\\vec{w},b) = -\\frac{1}{m_{train}} \\sum\\limits_{i = 1}^{m_{train}} [y^{(i)}\\log(f_{\\vec{w}, b}(\\vec{x}^{(i)})) + (1 - y^{(i)})\\log(1 - f_{\\vec{w}, b}(\\vec{x}^{(i)}))] + \\frac{\\lambda}{2m_{train}}\\sum_{j=1}^{n} w_j^2$$ Compute Test Error:$$J_{text}(\\vec{w},b) = -\\frac{1}{m_{test}} \\sum\\limits_{i = 1}^{m_{test}} [y_{test}^{(i)} \\log(f_{\\vec{w}, b}(\\vec{x_{test}}^{(i)})) + (1 - y_{test}^{(i)})\\log(1 - f_{\\vec{w}, b}(\\vec{x}_{test}^{(i)}))]$$ Compute Train Error:$$J_{train}(\\vec{w},b) = -\\frac{1}{m_{train}} \\sum\\limits_{i = 1}^{m_{train}} [y_{train}^{(i)}\\log(f_{\\vec{w}, b}(\\vec{x_{train}}^{(i)})) + (1 - y_{train}^{(i)})\\log(1 - f_{\\vec{w}, b}(\\vec{x}_{train}^{(i)}))]$$ Common Method for train and test error in classification model:$J_{test}(\\vec{w}, b)$ is the fraction of the test set that has been misclassified.$J_{train}(\\vec{w}, b)$ is the fraction of the train set that has been misclassified. Model SelectionTrain Cross-Validation Test SplitSplit dataset into 60% for training, 20% for cross-validation and 20% for testing. Evaluate and ChooseTrain all models on the training set. Evaluate all models on cross-validation set and pick the best one. Then give a fair estimate value of accuracy of the chosen model using test set.","link":"/2025/01/17/AI/machine_learning/notes/model_evaluation/"},{"title":"Math In Machine Learning","text":"Mathematics in machine learning~ IQR (Interquartile Range)IQR is a method to detect outliers in dataset. It describes the distance between the 1st quartile and the 3rd quartile. outliers are data &lt; Q1 - 1.5 * IQR, and data &gt; Q3 + 1.5 * IQR Variance and Standard DeviationVarianceVariance describes how a group of single data distribute from their mean. It measures the dispersion degree (离散程度). The more variance is, the more dispersive the data distributes. Standard DeviationStandard Deviation is the square root of variance. Compared to variance, standard deviation is more helpful to compare the dispersion degree of the data. Standard Deviation has the same dimension as the original data. Covariance and CorrelationCovarianceBetween two groups of variables, Covariance describes when one variable changes, how will another one change. It measures the linear relationship between two variables. The value of covariance is between $-\\infty$ and $+\\infty$.When it equals to 0, it means there is no linear relationship between these two variables. CorrelationThe correlation between two variables describes how strong the relationship between two variables. The value of correlation is between -1 and +1.","link":"/2025/01/25/AI/machine_learning/notes/math_in_machinelearning/"},{"title":"Python Basic","text":"Python basic knowledge~~ 列表创建 创建一个一维空列表, 长度为01nums = [] 创建一个二维空列表, 行和列长度为n1nums = [[None for _ in range(n)] for _ in range(n)] 列表的几种遍历方式: 从0到nums列表最后一位顺序遍历法, i表示下标 (nums[0], nums[1]...nums[n-1]) 1for i in range(len(nums)) 遍历由[left, right]左右闭区间组成的nums子串, x表示这个区间的每一个nums元素 1for x in nums[left:right] 从left下标开始, 到right-1结束, 以step为步长, 遍历这个区间. i表示下标 12345for i in range(left, right, step)# 注意: 遍历区间是**左闭右开**区间, 即`[left, right)`.# 如果需要左右闭区间遍历, 则需要: `range(left, right + 1, step)`# 反向闭区间遍历: `range(left - 1, right, step)` 从left下标开始, 到right-1结束, 以step为步长, 遍历这个区间. i表示下标 1for i in range(left, right, step) 列表获取子区间 123[x for x in nums[left:right]][nums[i] for i in range(left, right, step)] 列表添加元素 添加单个元素到列表尾部, 如nums.append(x) 1append() 添加一个可迭代对象（如列表、元组、字符串等）的所有元素到列表尾部, 如nums.extend([4, 5, 6]) 1extend() ‘for’ loopsfor循环遍历时的参数设置","link":"/2024/07/03/python/basic/"},{"title":"math","text":"How to calculate mathematics in python covariancenp.cov(x1, x2) correlation12numpy: np.corrcoef(x1, x2)pandas: df.corr()","link":"/2025/01/27/python/math/"},{"title":"Numpy","text":"Applications in numpy reshape numpy array.reshape()","link":"/2025/01/27/python/numpy/"},{"title":"Pandas","text":"Applications in pandas “pandas is kind of excel in python” Dataframe12345# 创建一个示例 DataFramedf = pd.DataFrame({'A': [1, 2, 3],'B': [4, 5, 6]}) Dataframe to numpy:df.to_numpy() Numpy to Dataframe:df = pd.Dataframe(array) drop some columns:12column_list = ['1', '2', '3']df = df.drop(column_list, axis=1) # drop some columns","link":"/2025/01/27/python/pandas/"},{"title":"Plotting Data","text":"How to plot charts for dataset heatmap 热区图123456# Seaborn Libraryimport seaborn as snfig, ax = plt.subplots(figsize=(10, 5))corr = df.corr()sn.heatmap(corr, annot=True) histogram 柱状图, 直方图12345# matplot libraryimport matplotlib.pyplot as pltfig, ax = plt.subplots(row_num, column_num)df.hist(axis=ax, edgecolor='black', grid=True) scatter 点图12345678910# matplot libraryfig, ax = plt.subplots(row_num, column_num, figsize=(24, 4), sharey=True) # sharey: 共享y坐标系y = df['label'].to_numpy()for i in range(len(ax)): X = df[column_list[i]].to_numpy() ax[i].scatter(X, y) ax[i].set_xlabel(column_list[i])ax[0].set_ylabel('Label')plt.show()","link":"/2025/01/27/python/plotting/"},{"title":"Python Virtual Environment","text":"Python Venv 搭建个人python虚拟环境 新建一个文件夹目录, 假设叫做“deeplearning”. 执行 python3 -m venv venv, 第一个“venv”表示创建virtual environment, 后面的“venv”表示环境文件夹命名. 执行 source venv/bin/activate以激活python虚拟环境, 回车后看到后续命令行内容中包含(venv)表示已经成功进入python虚拟环境. python虚拟环境安装jupyter 安装 Jupyter 1pip install notebook jupyterlab ipykernel 安装 IPython 内核 1pip install ipykernel 添加虚拟环境到 Jupyter 123python -m ipykernel install --user --name=myenv --display-name &quot;Python (myenv)&quot;myenv: 对应自己环境名称修改 从已有环境导出package list, 并在虚拟环境安装该package list 123pip freeze &gt; requirements.txt pip install -r requirements.txt 软链接和硬链接 Hard Link (硬链接)硬链接是文件系统中的一个直接指针，多个硬链接共享同一份文件数据。 123ln 源文件 链接名称ln file.txt file_hardlink.txt Symbolic Link (软链接)软链接类似于快捷方式，指向源文件的路径，而不是文件数据本身。 123ln -s 源目标target 链接名称ln -s /usr/local/bin/python3 /usr/bin/python3 替换系统默认的Python3符号链接","link":"/2025/01/27/python/virtual_environment/"},{"title":"Tensorflow And Pytorch","text":"Applications in tensorflow and pytorch. Tensorflow transform “pandas.dataframe” to “tensorflow.dataset” For training dataset, you should set the “label” to be the prediction label. In the “Titanic Survivors Prediction”, the label should be set to “Survived”. 1234# tfdf: tensorflow_decision_foreststrain_ds = tfdf.keras.pd_dataframe_to_tf_dataset(pandans_train_dataframe, label=&quot;Survived&quot;)test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(pandans_test_dataframe) PyTorch flatten (扁平化)torch.flatten(tensor)","link":"/2025/01/27/python/tensorflow_pytorch/"}],"tags":[{"name":"iOS","slug":"iOS","link":"/tags/iOS/"},{"name":"第三方库","slug":"第三方库","link":"/tags/%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/"},{"name":"ARC","slug":"ARC","link":"/tags/ARC/"},{"name":"NSThread","slug":"NSThread","link":"/tags/NSThread/"},{"name":"Objective-C","slug":"Objective-C","link":"/tags/Objective-C/"},{"name":"数据竞争","slug":"数据竞争","link":"/tags/%E6%95%B0%E6%8D%AE%E7%AB%9E%E4%BA%89/"},{"name":"gcd","slug":"gcd","link":"/tags/gcd/"},{"name":"死锁","slug":"死锁","link":"/tags/%E6%AD%BB%E9%94%81/"},{"name":"pthread","slug":"pthread","link":"/tags/pthread/"},{"name":"设计模式","slug":"设计模式","link":"/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"多线程","slug":"多线程","link":"/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"TODO","slug":"TODO","link":"/tags/TODO/"},{"name":"markdown","slug":"markdown","link":"/tags/markdown/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"ML","slug":"ML","link":"/tags/ML/"},{"name":"Interviews","slug":"Interviews","link":"/tags/Interviews/"},{"name":"Kaggle","slug":"Kaggle","link":"/tags/Kaggle/"}],"categories":[{"name":"iOS","slug":"iOS","link":"/categories/iOS/"},{"name":"Objective-C","slug":"iOS/Objective-C","link":"/categories/iOS/Objective-C/"},{"name":"第三方库","slug":"iOS/第三方库","link":"/categories/iOS/%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/"},{"name":"内存管理","slug":"iOS/内存管理","link":"/categories/iOS/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"},{"name":"多线程","slug":"iOS/多线程","link":"/categories/iOS/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"设计模式","slug":"iOS/设计模式","link":"/categories/iOS/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"TODO","slug":"TODO","link":"/categories/TODO/"},{"name":"markdown","slug":"markdown","link":"/categories/markdown/"},{"name":"Python","slug":"Python","link":"/categories/Python/"},{"name":"Interviews","slug":"iOS/Interviews","link":"/categories/iOS/Interviews/"},{"name":"Deep Learning","slug":"Deep-Learning","link":"/categories/Deep-Learning/"},{"name":"Supervised Learning","slug":"Deep-Learning/Supervised-Learning","link":"/categories/Deep-Learning/Supervised-Learning/"},{"name":"Image Classify","slug":"Deep-Learning/Supervised-Learning/Image-Classify","link":"/categories/Deep-Learning/Supervised-Learning/Image-Classify/"},{"name":"Face Recognition","slug":"Deep-Learning/Supervised-Learning/Face-Recognition","link":"/categories/Deep-Learning/Supervised-Learning/Face-Recognition/"},{"name":"CNN","slug":"Deep-Learning/Supervised-Learning/CNN","link":"/categories/Deep-Learning/Supervised-Learning/CNN/"},{"name":"Object Detection","slug":"Deep-Learning/Supervised-Learning/Object-Detection","link":"/categories/Deep-Learning/Supervised-Learning/Object-Detection/"},{"name":"Kaggle","slug":"Kaggle","link":"/categories/Kaggle/"},{"name":"Machine Learning","slug":"Machine-Learning","link":"/categories/Machine-Learning/"},{"name":"Supervised Learning","slug":"Machine-Learning/Supervised-Learning","link":"/categories/Machine-Learning/Supervised-Learning/"},{"name":"Logistic Regression","slug":"Machine-Learning/Supervised-Learning/Logistic-Regression","link":"/categories/Machine-Learning/Supervised-Learning/Logistic-Regression/"},{"name":"Linear Regression","slug":"Machine-Learning/Supervised-Learning/Linear-Regression","link":"/categories/Machine-Learning/Supervised-Learning/Linear-Regression/"},{"name":"Standard Neural Network","slug":"Deep-Learning/Supervised-Learning/Standard-Neural-Network","link":"/categories/Deep-Learning/Supervised-Learning/Standard-Neural-Network/"},{"name":"Model Optimization","slug":"Machine-Learning/Supervised-Learning/Model-Optimization","link":"/categories/Machine-Learning/Supervised-Learning/Model-Optimization/"},{"name":"Basic","slug":"Python/Basic","link":"/categories/Python/Basic/"},{"name":"Math","slug":"Python/Math","link":"/categories/Python/Math/"},{"name":"Numpy","slug":"Python/Numpy","link":"/categories/Python/Numpy/"},{"name":"Pandas","slug":"Python/Pandas","link":"/categories/Python/Pandas/"},{"name":"Plot","slug":"Python/Plot","link":"/categories/Python/Plot/"},{"name":"Scikit Learn","slug":"Python/Scikit-Learn","link":"/categories/Python/Scikit-Learn/"},{"name":"Venv","slug":"Python/Venv","link":"/categories/Python/Venv/"},{"name":"Model","slug":"Python/Model","link":"/categories/Python/Model/"}],"pages":[]}